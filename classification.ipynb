{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from torchvision.transforms import ToTensor, Compose\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import os\n",
    "import random\n",
    "import datetime\n",
    "from copy import deepcopy\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from utils.dataset import CutOrPad, get_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PASTIS9 = './data/PASTIS9/'\n",
    "PATH = PASTIS9\n",
    "files = os.listdir(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['img', 'labels', 'doy'])\n",
      "Image:  (38, 10, 9, 9)\n",
      "Labels:  () 19.0\n",
      "DOY:  (38,) [ 15  45  55  80  90 105 110 115 135 145 150 155 170 175 180 185 190 205\n",
      " 210 215 220 230 235 240 245 255 260 260 265 265 270 285 285 295 315 345\n",
      " 350 360]\n"
     ]
    }
   ],
   "source": [
    "file = random.choice(files)\n",
    "data = pd.read_pickle(PATH + file)\n",
    "\n",
    "print(data.keys())\n",
    "print('Image: ', data['img'].shape)\n",
    "print('Labels: ', data['labels'].shape, data['labels'])\n",
    "print('DOY: ', data['doy'].shape, data['doy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PASTIS(Dataset):\n",
    "    def __init__(self, pastis_path):\n",
    "        self.pastis_path = pastis_path\n",
    "\n",
    "        self.file_names = os.listdir(self.pastis_path)[:500]\n",
    "\n",
    "        random.shuffle(self.file_names)\n",
    "\n",
    "        self.to_cutorpad = CutOrPad()\n",
    "        # self.to_tiledates = TileDates(24, 24)\n",
    "        # self.to_unkmask = UnkMask(unk_class=19, ground_truth_target='labels'))\n",
    "\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_names)\n",
    "\n",
    "\n",
    "    def add_date_channel(self, img, doy):\n",
    "        img = torch.cat((img, doy), dim=1)\n",
    "        return img\n",
    "\n",
    "\n",
    "    def normalize(self, img):\n",
    "        C = img.shape[1]\n",
    "        mean = img.mean(dim=(0, 2, 3)).to(torch.float32).reshape(1, C, 1, 1)\n",
    "        std = img.std(dim=(0, 2, 3)).to(torch.float32).reshape(1, C, 1, 1)\n",
    "\n",
    "        img = (img - mean) / std\n",
    "\n",
    "        return img\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = pd.read_pickle(os.path.join(self.pastis_path, self.file_names[idx]))\n",
    "\n",
    "        data['img'] = data['img'].astype('float32')\n",
    "        data['img'] = torch.tensor(data['img'])\n",
    "        data['img'] = self.normalize(data['img'])\n",
    "        T, C, H, W = data['img'].shape\n",
    "\n",
    "        data['labels'] = data['labels'].astype('long')\n",
    "        data['labels'] = torch.tensor(data['labels'])\n",
    "        # data['labels'] = F.one_hot(data['labels'].long(), num_classes=20)\n",
    "\n",
    "        data['doy'] = data['doy'].astype('float32')\n",
    "        data['doy'] = torch.tensor(data['doy'])\n",
    "        data['doy'] = data['doy'].unsqueeze(1).unsqueeze(1).unsqueeze(1)\n",
    "        data['doy'] = data['doy'].repeat(1, 1, H, W)\n",
    "\n",
    "        data['img'] = self.add_date_channel(data['img'], data['doy']) # add DOY to the last channel\n",
    "        del data['doy'] # Delete DOY\n",
    "\n",
    "        data = self.to_cutorpad(data) # Pad to Max Sequence Length\n",
    "        del data['seq_lengths'] # Delete Sequence Length\n",
    "\n",
    "\n",
    "        return data['img'], data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = PASTIS(PATH)\n",
    "data.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set = random_split(data, [400, 100])\n",
    "train_loader = DataLoader(train_set, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAGdCAYAAAAv9mXmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAZ5UlEQVR4nO3dfXBUhb3/8U9IzCboEnkKkEsCkbYi4UEgwIW0PlTEyQ8Y7fTS6sRpCr29rQ0CZuo0aQcpQ2Gh0zLpAA0PPwrMSAR6W9Q6gwykA5RiSgjikGpB1MIqkvi4C0EWzO79o3PTm0rYnGS/OTnx/ZrZGbNz1vOZheE9Zxd2k2KxWEwAACRYL7cHAAB6JgIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMpHT1CaPRqM6fPy+/36+kpKSuPj0AoBNisZguXryorKws9ep142uULg/M+fPnlZ2d3dWnBQAkUDAY1NChQ294TJcHxu/3S5JW/WeZ0lN9XX36dvskZYTbE+IKqsntCXEd+fNetyfEdXPvqNsT2uWmW7r/K9pXrnzg9oS4Xnv7Y7cnxPXRu5fdntC2WFRqeqvlz/Ib6fLA/O/LYumpPqX70rr69O0WS+nt9oS4fOr+fzAmJ9/k9oS4UlK6//MoSSk3df/ApHza5X+kOJaUnOz2hPiSuv/G9rzF0f1/xwIAPInAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmOhSYdevWafjw4UpLS9OUKVN09OjRRO8CAHic48Ds3LlTpaWlWrJkiY4fP65x48bpgQceUGNjo8U+AIBHOQ7M6tWr9d3vfldz587VqFGjtH79evXu3Vu/+c1vLPYBADzKUWCuXr2quro6TZ8+/Z//g169NH36dL300kvXfUwkElE4HG51AwD0fI4C8/7776u5uVmDBg1qdf+gQYN04cKF6z4mEAgoIyOj5Zadnd3xtQAAzzD/W2Tl5eUKhUItt2AwaH1KAEA34OgLtAcMGKDk5GQ1NDS0ur+hoUGDBw++7mN8Pp98Pl/HFwIAPMnRFUxqaqomTpyo6urqlvui0aiqq6s1derUhI8DAHiXoysYSSotLVVxcbHy8/M1efJkVVRUqKmpSXPnzrXYBwDwKMeB+eY3v6n33ntPTz31lC5cuKA777xTL7744mfe+AcAfL45DowkzZ8/X/Pnz0/0FgBAD8JnkQEATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMBEhz5NORHSvjhC6em93Tp9XKffetPtCXFFLze5PSGu3MyRbk+Iq/7CMbcntMuHB4+7PSGuj6MN8Q9yWb8JE92eENeQ8dPcntCm6KdX1XDkjXYdyxUMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmHAfm0KFDmj17trKyspSUlKRnn33WYBYAwOscB6apqUnjxo3TunXrLPYAAHoIx1+ZXFhYqMLCQostAIAexHFgnIpEIopEIi0/h8Nh61MCALoB8zf5A4GAMjIyWm7Z2dnWpwQAdAPmgSkvL1coFGq5BYNB61MCALoB85fIfD6ffD6f9WkAAN0M/w4GAGDC8RXMpUuXdObMmZaf33rrLZ04cUL9+vVTTk5OQscBALzLcWCOHTume++9t+Xn0tJSSVJxcbG2bt2asGEAAG9zHJh77rlHsVjMYgsAoAfhPRgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYMP9Gy7ZcDL2hTyNpbp0+rkz/rW5PiGtAfj+3J8Q1bHT3/zbT3sEGtye0y4nm7v8p5oOT3V4QX0Zyf7cnxNU4bqDbE9rUfDWihiPtO5YrGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATDgKTCAQ0KRJk+T3+5WZmamHHnpIp06dstoGAPAwR4E5ePCgSkpKVFNTo3379unatWuaMWOGmpqarPYBADzK0Vcmv/jii61+3rp1qzIzM1VXV6e77rorocMAAN7mKDD/KhQKSZL69Wv7u+EjkYgikUjLz+FwuDOnBAB4RIff5I9Go1q0aJEKCgo0evToNo8LBALKyMhouWVnZ3f0lAAAD+lwYEpKSlRfX68dO3bc8Ljy8nKFQqGWWzAY7OgpAQAe0qGXyObPn68XXnhBhw4d0tChQ294rM/nk8/n69A4AIB3OQpMLBbT448/rt27d+vAgQPKzc212gUA8DhHgSkpKVFVVZWee+45+f1+XbhwQZKUkZGh9PR0k4EAAG9y9B5MZWWlQqGQ7rnnHg0ZMqTltnPnTqt9AACPcvwSGQAA7cFnkQEATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMBEh77RMhHOv3lFvtTu++nMN09sdntCXO98mOH2hLgaX7/o9oS4Pv6o+/9aS9KtA7PdnhDXuKxRbk+IK2Ns9/+G3ZSs3m5PaNOVy59oxYb2HcsVDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJhwFprKyUmPHjlWfPn3Up08fTZ06VXv27LHaBgDwMEeBGTp0qFauXKm6ujodO3ZMX/3qV/Xggw/qr3/9q9U+AIBHOfrK5NmzZ7f6efny5aqsrFRNTY3y8vISOgwA4G2OAvN/NTc367e//a2ampo0derUNo+LRCKKRCItP4fD4Y6eEgDgIY7f5D958qRuueUW+Xw+ff/739fu3bs1atSoNo8PBALKyMhouWVnZ3dqMADAGxwH5vbbb9eJEyf0l7/8RY899piKi4v16quvtnl8eXm5QqFQyy0YDHZqMADAGxy/RJaamqovfOELkqSJEyeqtrZWv/rVr7Rhw4brHu/z+eTz+Tq3EgDgOZ3+dzDRaLTVeywAAEgOr2DKy8tVWFionJwcXbx4UVVVVTpw4ID27t1rtQ8A4FGOAtPY2Khvfetbevfdd5WRkaGxY8dq7969uv/++632AQA8ylFgNm/ebLUDANDD8FlkAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMOH4Gy0T5YKuKlVJbp0+rtj7H7g9Ia6L56JuT4jr0qvvuz0hrnc+fNvtCe0yOCvD7QlxvZfa4PaE+ELd/3nsk9Lk9oQ2ffrJlXYfyxUMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmOhWYlStXKikpSYsWLUrQHABAT9HhwNTW1mrDhg0aO3ZsIvcAAHqIDgXm0qVLKioq0qZNm9S3b99EbwIA9AAdCkxJSYlmzpyp6dOnxz02EokoHA63ugEAer4Upw/YsWOHjh8/rtra2nYdHwgEtHTpUsfDAADe5ugKJhgMauHChdq+fbvS0tLa9Zjy8nKFQqGWWzAY7NBQAIC3OLqCqaurU2NjoyZMmNByX3Nzsw4dOqS1a9cqEokoOTm51WN8Pp98Pl9i1gIAPMNRYO677z6dPHmy1X1z587VyJEj9aMf/egzcQEAfH45Cozf79fo0aNb3XfzzTerf//+n7kfAPD5xr/kBwCYcPy3yP7VgQMHEjADANDTcAUDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAE53+NOWOejfyoVJiqW6dPq6P/zvk9oS4+vovuj0hrrTkXLcnxDWk37+5PaFdUuvDbk+Iq/7Dv7k9Ia7euYPdnhBX5uBBbk9o07WrkXYfyxUMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmHAXmpz/9qZKSklrdRo4cabUNAOBhjr/RMi8vT/v37//n/yDFtS/FBAB0Y47rkJKSosGDu/9XjgIA3OX4PZjXX39dWVlZuu2221RUVKRz585Z7AIAeJyjK5gpU6Zo69atuv322/Xuu+9q6dKl+spXvqL6+nr5/f7rPiYSiSgSibT8HA6HO7cYAOAJjgJTWFjY8t9jx47VlClTNGzYMO3atUvf+c53rvuYQCCgpUuXdm4lAMBzOvXXlG+99VZ96Utf0pkzZ9o8pry8XKFQqOUWDAY7c0oAgEd0KjCXLl3SG2+8oSFDhrR5jM/nU58+fVrdAAA9n6PA/PCHP9TBgwf197//XUeOHNHXvvY1JScn65FHHrHaBwDwKEfvwbz99tt65JFH9MEHH2jgwIH68pe/rJqaGg0cONBqHwDAoxwFZseOHVY7AAA9DJ9FBgAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBgwtHH9SfUB2Ep5SbXTh9PrGmw2xPiyrzPvV++9vqgIer2hLiuvdHs9oR2SZpyxe0JcX1ytfv/eueOz3J7Qlz33neb2xPadKXpsvb8//YdyxUMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMOE4MO+8844effRR9e/fX+np6RozZoyOHTtmsQ0A4GGOvrHqo48+UkFBge69917t2bNHAwcO1Ouvv66+ffta7QMAeJSjwKxatUrZ2dnasmVLy325ubkJHwUA8D5HL5E9//zzys/P15w5c5SZmanx48dr06ZNVtsAAB7mKDBvvvmmKisr9cUvflF79+7VY489pgULFmjbtm1tPiYSiSgcDre6AQB6PkcvkUWjUeXn52vFihWSpPHjx6u+vl7r169XcXHxdR8TCAS0dOnSzi8FAHiKoyuYIUOGaNSoUa3uu+OOO3Tu3Lk2H1NeXq5QKNRyCwaDHVsKAPAUR1cwBQUFOnXqVKv7Tp8+rWHDhrX5GJ/PJ5/P17F1AADPcnQF88QTT6impkYrVqzQmTNnVFVVpY0bN6qkpMRqHwDAoxwFZtKkSdq9e7eeeeYZjR49WsuWLVNFRYWKioqs9gEAPMrRS2SSNGvWLM2aNctiCwCgB+GzyAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATDj+uP5ESRrQR0mpqW6dPq7/N3Oa2xPiGpnW7PaEuF4KHnR7Qlx/fO0Dtye0yy25g92eENfo+/1uT4hr9uT73Z4Q19xJ/+72hDaFw2GV6b/adSxXMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmHAUmOHDhyspKekzt5KSEqt9AACPcvSNlrW1tWpu/ue3KNbX1+v+++/XnDlzEj4MAOBtjgIzcODAVj+vXLlSI0aM0N13353QUQAA73MUmP/r6tWrevrpp1VaWqqkpKQ2j4tEIopEIi0/h8Phjp4SAOAhHX6T/9lnn9XHH3+sb3/72zc8LhAIKCMjo+WWnZ3d0VMCADykw4HZvHmzCgsLlZWVdcPjysvLFQqFWm7BYLCjpwQAeEiHXiI7e/as9u/fr9///vdxj/X5fPL5fB05DQDAwzp0BbNlyxZlZmZq5syZid4DAOghHAcmGo1qy5YtKi4uVkpKh/+OAACgh3McmP379+vcuXOaN2+exR4AQA/h+BJkxowZisViFlsAAD0In0UGADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAE659ocuD331A6bf0duv0cU1uvMXtCXG99arbC+K7acAotyfE5Z96ye0J7ZJ7+7+5PSGuknv+w+0JcfXKTXZ7QlzRpLfcntCmaNLFdh/LFQwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYcBaa5uVmLFy9Wbm6u0tPTNWLECC1btkyxWMxqHwDAoxx9o+WqVatUWVmpbdu2KS8vT8eOHdPcuXOVkZGhBQsWWG0EAHiQo8AcOXJEDz74oGbOnClJGj58uJ555hkdPXrUZBwAwLscvUQ2bdo0VVdX6/Tp05KkV155RYcPH1ZhYWGbj4lEIgqHw61uAICez9EVTFlZmcLhsEaOHKnk5GQ1Nzdr+fLlKioqavMxgUBAS5cu7fRQAIC3OLqC2bVrl7Zv366qqiodP35c27Zt0y9+8Qtt27atzceUl5crFAq13ILBYKdHAwC6P0dXME8++aTKysr08MMPS5LGjBmjs2fPKhAIqLi4+LqP8fl88vl8nV8KAPAUR1cwly9fVq9erR+SnJysaDSa0FEAAO9zdAUze/ZsLV++XDk5OcrLy9PLL7+s1atXa968eVb7AAAe5Sgwa9as0eLFi/WDH/xAjY2NysrK0ve+9z099dRTVvsAAB7lKDB+v18VFRWqqKgwmgMA6Cn4LDIAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwISjD7tMhFgsJkn6pOlyV5/akUuXk9yeENflK24viC9ytfuP/PTTa25PaJdrVyJuT4ir6dIltyfE1Suc7PaEuMLN3ff3ZDj8j1/j//2z/EaSYu05KoHefvttZWdnd+UpAQAJFgwGNXTo0Bse0+WBiUajOn/+vPx+v5KSOn+VEA6HlZ2drWAwqD59+iRg4ecTz2Ni8DwmDs9lYiT6eYzFYrp48aKysrI+8w3H/6rLXyLr1atX3Op1RJ8+ffhNmAA8j4nB85g4PJeJkcjnMSMjo13H8SY/AMAEgQEAmPB8YHw+n5YsWSKfz+f2FE/jeUwMnsfE4blMDDefxy5/kx8A8Png+SsYAED3RGAAACYIDADABIEBAJjwfGDWrVun4cOHKy0tTVOmTNHRo0fdnuQpgUBAkyZNkt/vV2Zmph566CGdOnXK7Vmet3LlSiUlJWnRokVuT/Gcd955R48++qj69++v9PR0jRkzRseOHXN7lqc0Nzdr8eLFys3NVXp6ukaMGKFly5a16/PDEsnTgdm5c6dKS0u1ZMkSHT9+XOPGjdMDDzygxsZGt6d5xsGDB1VSUqKamhrt27dP165d04wZM9TU1OT2NM+qra3Vhg0bNHbsWLeneM5HH32kgoIC3XTTTdqzZ49effVV/fKXv1Tfvn3dnuYpq1atUmVlpdauXavXXntNq1at0s9//nOtWbOmS3d4+q8pT5kyRZMmTdLatWsl/eNzzrKzs/X444+rrKzM5XXe9N577ykzM1MHDx7UXXfd5fYcz7l06ZImTJigX//61/rZz36mO++8UxUVFW7P8oyysjL9+c9/1p/+9Ce3p3jarFmzNGjQIG3evLnlvq9//etKT0/X008/3WU7PHsFc/XqVdXV1Wn69Okt9/Xq1UvTp0/XSy+95OIybwuFQpKkfv36ubzEm0pKSjRz5sxWvy/Rfs8//7zy8/M1Z84cZWZmavz48dq0aZPbszxn2rRpqq6u1unTpyVJr7zyig4fPqzCwsIu3dHlH3aZKO+//76am5s1aNCgVvcPGjRIf/vb31xa5W3RaFSLFi1SQUGBRo8e7fYcz9mxY4eOHz+u2tpat6d41ptvvqnKykqVlpbqxz/+sWpra7VgwQKlpqaquLjY7XmeUVZWpnA4rJEjRyo5OVnNzc1avny5ioqKunSHZwODxCspKVF9fb0OHz7s9hTPCQaDWrhwofbt26e0tDS353hWNBpVfn6+VqxYIUkaP3686uvrtX79egLjwK5du7R9+3ZVVVUpLy9PJ06c0KJFi5SVldWlz6NnAzNgwAAlJyeroaGh1f0NDQ0aPHiwS6u8a/78+XrhhRd06NAhk69T6Onq6urU2NioCRMmtNzX3NysQ4cOae3atYpEIkpO7v7fpOi2IUOGaNSoUa3uu+OOO/S73/3OpUXe9OSTT6qsrEwPP/ywJGnMmDE6e/asAoFAlwbGs+/BpKamauLEiaqurm65LxqNqrq6WlOnTnVxmbfEYjHNnz9fu3fv1h//+Efl5ua6PcmT7rvvPp08eVInTpxoueXn56uoqEgnTpwgLu1UUFDwmb8mf/r0aQ0bNsylRd50+fLlz3wZWHJysqLRaJfu8OwVjCSVlpaquLhY+fn5mjx5sioqKtTU1KS5c+e6Pc0zSkpKVFVVpeeee05+v18XLlyQ9I8vFEpPT3d5nXf4/f7PvG918803q3///ryf5cATTzyhadOmacWKFfrGN76ho0ePauPGjdq4caPb0zxl9uzZWr58uXJycpSXl6eXX35Zq1ev1rx587p2SMzj1qxZE8vJyYmlpqbGJk+eHKupqXF7kqdIuu5ty5Ytbk/zvLvvvju2cOFCt2d4zh/+8IfY6NGjYz6fLzZy5MjYxo0b3Z7kOeFwOLZw4cJYTk5OLC0tLXbbbbfFfvKTn8QikUiX7vD0v4MBAHRfnn0PBgDQvREYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJv4HGJ4WBPrK084AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = next(iter(train_loader))\n",
    "plt.imshow(get_rgb(img[0][:,:-1,:,:].numpy()))\n",
    "print(label[0].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, einsum\n",
    "from einops import rearrange\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "\n",
    "\n",
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, dim, fn):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x, **kwargs):\n",
    "        return self.fn(self.norm(x), **kwargs)\n",
    "\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, dropout=0.):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, heads=8, dim_head=64, dropout=0.):\n",
    "        super().__init__()\n",
    "        inner_dim = dim_head * heads\n",
    "        project_out = not (heads == 1 and dim_head == dim)\n",
    "\n",
    "        self.heads = heads\n",
    "        self.scale = dim_head ** -0.5\n",
    "\n",
    "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias=False)\n",
    "\n",
    "        self.to_out = nn.Sequential(\n",
    "            nn.Linear(inner_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        ) if project_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        b, n, _, h = *x.shape, self.heads\n",
    "        qkv = self.to_qkv(x).chunk(3, dim=-1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h=h), qkv)\n",
    "        # print(q.shape, k.shape, v.shape)\n",
    "        dots = einsum('b h i d, b h j d -> b h i j', q, k) * self.scale\n",
    "\n",
    "        attn = dots.softmax(dim=-1)\n",
    "\n",
    "        out = einsum('b h i j, b h j d -> b h i d', attn, v)\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "        out = self.to_out(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout=0.):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([])\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                PreNorm(dim, Attention(dim, heads=heads, dim_head=dim_head, dropout=dropout)),\n",
    "                PreNorm(dim, FeedForward(dim, mlp_dim, dropout=dropout))\n",
    "            ]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for attn, ff in self.layers:\n",
    "            x = attn(x) + x\n",
    "            x = ff(x) + x\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classification(nn.Module):\n",
    "    def __init__(self, img_height=9, img_width=9, in_channel=10,\n",
    "                       patch_size=3, embed_dim=128, max_time=60,\n",
    "                       num_classes=20, num_head=4, dim_feedforward=2048,\n",
    "                       num_layers=4, dropoutratio=0.5\n",
    "                ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.H = img_height\n",
    "        self.W = img_width\n",
    "        self.P = patch_size\n",
    "        self.C = in_channel\n",
    "        self.d = embed_dim\n",
    "        self.T = max_time\n",
    "        self.K = num_classes\n",
    "\n",
    "        self.d_model = self.d\n",
    "        self.num_head = num_head\n",
    "        self.dim_feedforward = self.d\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.N = int(self.H * self.W // self.P**2)\n",
    "        self.nh = int(self.H / self.P)\n",
    "        self.nw = int(self.W / self.P)\n",
    "\n",
    "        self.dropout = nn.Dropout(p=dropoutratio)\n",
    "        '''\n",
    "        PARAMETERS\n",
    "        '''\n",
    "        # Transformer Encoder\n",
    "\n",
    "        # PyTorch Encoder\n",
    "        # self.encoderLayer = nn.TransformerEncoderLayer(d_model=self.d_model, nhead=self.num_head, dim_feedforward=self.dim_feedforward)\n",
    "        # self.encoder = nn.TransformerEncoder(self.encoderLayer, num_layers=self.num_layers)\n",
    "\n",
    "        # DeepSat Encoder\n",
    "        self.encoder = Transformer(self.d, self.num_layers, self.num_head, 32, self.d*4, dropoutratio)\n",
    "\n",
    "\n",
    "        # torchvision Encoder\n",
    "        # self.encoder = Encoder(seq_length=self.N, num_heads=4, num_layers=4, hidden_dim=self.d, mlp_dim=self.d*4, dropout=0., attention_dropout=0.)\n",
    "\n",
    "\n",
    "        # Patches\n",
    "        self.projection = nn.Conv3d(self.C, self.d, kernel_size=(1, self.P, self.P), stride=(1, self.P, self.P))\n",
    "        '''\n",
    "        def __init__():\n",
    "            self.linear = nn.Linear(self.C*self.P**2, self.d)\n",
    "        def forward():\n",
    "            x = x.view(B, T, H // P, W // P, C*P**2)\n",
    "            x = self.linear(x)\n",
    "        '''\n",
    "\n",
    "        # Temporal\n",
    "        self.temporal_emb = nn.Linear(366, self.d)\n",
    "        self.temporal_cls_token = nn.Parameter(torch.randn(1, self.N, self.K, self.d)) # (N, K, d)\n",
    "        self.temporal_transformer = self.encoder\n",
    "\n",
    "        # Spatial\n",
    "        self.spatial_emb = nn.Parameter(torch.randn(1, self.N, self.d)) # (1, N, d)\n",
    "        self.spatial_cls_token = nn.Parameter(torch.randn(1, self.K, self.d)) # (1, K, d)\n",
    "        self.spatial_transformer = self.encoder\n",
    "\n",
    "        # Segmentation Head\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LayerNorm(self.d),\n",
    "            nn.Linear(self.d, 1)\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Tekenization\n",
    "\n",
    "        Convert the images to a sequence of patches\n",
    "        '''\n",
    "        x_sits = x[:, :, :-1, :, :] # (B, T, C, H, W) -- > Exclude DOY Channel\n",
    "        B, T, C, H, W = x_sits.shape # (B, T, C, H, W)\n",
    "        x_sits = x_sits.reshape(B, C, T, H, W) # (B, C, T, H, W)\n",
    "        x_sits = self.projection(x_sits) # (B, d, T, nw, nh)\n",
    "        # x_sits = self.dropout(x_sits) \n",
    "        x_sits = x_sits.reshape(B, self.d, T, self.nh*self.nw) # (B, d, T, N)\n",
    "        # x_sits = x_sits + self.pos_emb # (B, d, T, N)  we dont add pos embedding here, cuz we need the pure data for the temporal encoder\n",
    "        x_sits = x_sits.permute(0,3,2,1) # (B, N, T, d)\n",
    "\n",
    "\n",
    "\n",
    "        '''\n",
    "        Temporal Encoding\n",
    "\n",
    "        (DOY -> One-Hot -> Projection)\n",
    "        '''\n",
    "        xt = x[:, :, -1, 0, 0] # (B, T, C, H, W) in the last channel lies the DOY feature\n",
    "        xt = F.one_hot(xt.to(torch.int64), num_classes=366).to(torch.float32) # (B, T, 366)\n",
    "        Pt = self.temporal_emb(xt) # (B, T, d) (DOY, one-hot encoded to represent the DOY feature and then encoded to d dimensions)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        '''\n",
    "        Temporal Encoder: cat(Z+Pt)\n",
    "\n",
    "        add temporal embeddings (N*K) to the Time Series patches (T)\n",
    "        '''\n",
    "        x = x_sits + Pt.unsqueeze(1) # (B, N, T, d)\n",
    "        # x = self.dropout(x)\n",
    "        temporal_cls_token = self.temporal_cls_token # (1, N, K, d)\n",
    "        temporal_cls_token = temporal_cls_token.repeat(B, 1, 1, 1) # (B, N, K, d)\n",
    "        temporal_cls_token = temporal_cls_token.reshape(B*self.N, self.K, self.d) # (B*N, K, d)\n",
    "        x = x.reshape(B*self.N, T, self.d) # (B*N, T, d)\n",
    "        # Temporal Tokens (N*K)\n",
    "        x = torch.cat([temporal_cls_token, x], dim=1) # (B*N, K+T, d)\n",
    "        # Temporal Transformer\n",
    "        x = self.temporal_transformer(x) # (B*N, K+T, d)\n",
    "        x = x.reshape(B, self.N, self.K + T, self.d) # (B, N, K+T, d)\n",
    "        x = x[:,:,:self.K,:] # (B, N, K, d)\n",
    "        x = x.permute(0, 2, 1, 3) # (B, K, N, d)\n",
    "        x = x.reshape(B*(self.K), self.N, self.d) # (B*K, N, d)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        '''\n",
    "        Spatial Encoding\n",
    "        '''\n",
    "        Ps = self.spatial_emb # (1, N, d)\n",
    "        x = x + Ps # (B*K, N, d)\n",
    "        x = self.dropout(x)\n",
    "        # For Classification Only\n",
    "        spatial_cls_token = self.spatial_cls_token # (1, K, d)\n",
    "        spatial_cls_token = spatial_cls_token.unsqueeze(2) # (1, K, 1, d)\n",
    "        spatial_cls_token = spatial_cls_token.repeat(B, 1, 1, 1) # (B, K, 1, d)\n",
    "        spatial_cls_token = spatial_cls_token.reshape(B*self.K, 1, self.d) # (B*K, 1, d)\n",
    "        x = torch.cat([spatial_cls_token, x], dim=1) # (B*K, 1+N, d)\n",
    "        x = self.spatial_transformer(x) # (B*K, N+1, d)\n",
    "        # x = self.dropout(x)\n",
    "\n",
    "\n",
    "        '''\n",
    "        Classification Head\n",
    "        '''\n",
    "        classes = x[:,0,:] # (B*K, d)\n",
    "        classes = classes.reshape(B, self.K, self.d) # (B, K, d)\n",
    "        \n",
    "        x = self.mlp_head(classes) # (B, K, 1)\n",
    "        x = x.reshape(B, self.K) # (B, K)\n",
    "\n",
    "\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Credits to  github.com/clcarwin/focal_loss_pytorch\n",
    "    \"\"\"\n",
    "    def __init__(self, gamma=8, alpha=torch.ones(20), reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        if isinstance(alpha, (float, int)): self.alpha = torch.Tensor([alpha, 1 - alpha])\n",
    "        if isinstance(alpha, list): self.alpha = torch.Tensor(alpha)\n",
    "        self.reduction = reduction\n",
    "        \n",
    "    def forward(self, input, target):\n",
    "        if input.dim() > 2:\n",
    "            input = input.view(input.size(0), input.size(1), -1)  # N,C,H,W => N,C,H*W\n",
    "            input = input.transpose(1, 2)  # N,C,H*W => N,H*W,C\n",
    "            input = input.contiguous().view(-1, input.size(2))  # N,H*W,C => N*H*W,C\n",
    "        target = target.view(-1, 1)\n",
    "\n",
    "        logpt = F.log_softmax(input, dim=1)\n",
    "        logpt = logpt.gather(1, target)\n",
    "        logpt = logpt.view(-1)\n",
    "        pt = Variable(logpt.data.exp())\n",
    "\n",
    "        if self.alpha is not None:\n",
    "            if self.alpha.type() != input.data.type():\n",
    "                self.alpha = self.alpha.type_as(input.data)\n",
    "            at = self.alpha.gather(0, target.data.view(-1))\n",
    "            logpt = logpt * Variable(at)\n",
    "\n",
    "        loss = -1 * (1 - pt) ** self.gamma * logpt\n",
    "        if self.reduction is None:\n",
    "            return loss\n",
    "        elif self.reduction == \"mean\":\n",
    "            return loss.mean()\n",
    "        elif self.reduction == \"sum\":\n",
    "            return loss.sum()\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"FocalLoss: reduction parameter not in list of acceptable values [\\\"mean\\\", \\\"sum\\\", None]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Parameters:  1273345\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Classification(\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (encoder): Transformer(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Attention(\n",
       "            (to_qkv): Linear(in_features=128, out_features=384, bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (1): Dropout(p=0.5, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): FeedForward(\n",
       "            (net): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.5, inplace=False)\n",
       "              (3): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (4): Dropout(p=0.5, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (projection): Conv3d(10, 128, kernel_size=(1, 3, 3), stride=(1, 3, 3))\n",
       "  (temporal_emb): Linear(in_features=366, out_features=128, bias=True)\n",
       "  (temporal_transformer): Transformer(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Attention(\n",
       "            (to_qkv): Linear(in_features=128, out_features=384, bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (1): Dropout(p=0.5, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): FeedForward(\n",
       "            (net): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.5, inplace=False)\n",
       "              (3): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (4): Dropout(p=0.5, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (spatial_transformer): Transformer(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Attention(\n",
       "            (to_qkv): Linear(in_features=128, out_features=384, bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (1): Dropout(p=0.5, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): FeedForward(\n",
       "            (net): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.5, inplace=False)\n",
       "              (3): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (4): Dropout(p=0.5, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (mlp_head): Sequential(\n",
       "    (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Data\n",
    "batch_size = 8\n",
    "\n",
    "# Model\n",
    "model = Classification(img_width=9, img_height=9, in_channel=10, patch_size=3, embed_dim=128, max_time=60, num_head=4, num_layers=6, num_classes=20)\n",
    "model.to(device)\n",
    "\n",
    "num_samples = train_loader.__len__()*batch_size\n",
    "\n",
    "num_params = sum([p.numel() for p in model.parameters() if p.requires_grad == True])\n",
    "print('Number of Parameters: ', num_params)\n",
    "\n",
    "# Loss\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion = FocalLoss()\n",
    "# criterion = nn.MSELoss()\n",
    "\n",
    "# Optimizer\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "epochs = 200\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 25.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 Loss:  tensor(12.9140, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 Loss:  tensor(10.8758, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 45.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2 Loss:  tensor(10.8166, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 43.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3 Loss:  tensor(10.4740, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4 Loss:  tensor(10.5409, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5 Loss:  tensor(10.1680, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 47.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  6 Loss:  tensor(10.1514, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 47.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  7 Loss:  tensor(9.9712, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  8 Loss:  tensor(10.0372, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 45.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  9 Loss:  tensor(10.1721, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 44.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  10 Loss:  tensor(10.0184, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 44.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  11 Loss:  tensor(10.2046, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 44.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  12 Loss:  tensor(10.0178, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 45.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  13 Loss:  tensor(9.9785, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 44.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  14 Loss:  tensor(10.0218, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 44.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  15 Loss:  tensor(10.0331, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 38.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  16 Loss:  tensor(9.9843, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 40.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  17 Loss:  tensor(10.0402, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 44.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  18 Loss:  tensor(9.9938, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 45.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  19 Loss:  tensor(10.0379, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  20 Loss:  tensor(10.0594, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  21 Loss:  tensor(9.9281, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  22 Loss:  tensor(9.9960, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  23 Loss:  tensor(9.8742, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 44.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  24 Loss:  tensor(9.7996, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 40.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  25 Loss:  tensor(10.1176, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 42.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  26 Loss:  tensor(9.8890, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 42.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  27 Loss:  tensor(9.9468, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 45.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  28 Loss:  tensor(9.8969, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 45.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  29 Loss:  tensor(9.8680, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 42.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  30 Loss:  tensor(9.7558, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 43.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  31 Loss:  tensor(9.7963, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 45.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  32 Loss:  tensor(9.6681, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 44.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  33 Loss:  tensor(9.3855, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 45.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  34 Loss:  tensor(9.5058, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 45.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  35 Loss:  tensor(9.3339, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 43.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  36 Loss:  tensor(9.1022, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  37 Loss:  tensor(8.9878, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 44.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  38 Loss:  tensor(8.8490, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 45.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  39 Loss:  tensor(8.5934, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 45.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  40 Loss:  tensor(8.2525, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  41 Loss:  tensor(8.4291, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  42 Loss:  tensor(7.9110, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  43 Loss:  tensor(7.5029, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 42.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  44 Loss:  tensor(7.2679, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 45.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  45 Loss:  tensor(7.2742, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  46 Loss:  tensor(6.7666, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  47 Loss:  tensor(6.5566, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  48 Loss:  tensor(5.8860, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  49 Loss:  tensor(5.8250, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 37.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  50 Loss:  tensor(5.9040, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  51 Loss:  tensor(4.8997, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 42.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  52 Loss:  tensor(4.4308, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  53 Loss:  tensor(3.9613, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  54 Loss:  tensor(2.9745, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  55 Loss:  tensor(3.2704, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  56 Loss:  tensor(3.5592, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 44.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  57 Loss:  tensor(2.4523, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  58 Loss:  tensor(2.2135, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 47.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  59 Loss:  tensor(2.2119, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  60 Loss:  tensor(1.5775, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  61 Loss:  tensor(2.6455, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 45.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  62 Loss:  tensor(3.1356, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  63 Loss:  tensor(1.8422, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 43.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  64 Loss:  tensor(1.0591, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  65 Loss:  tensor(0.9438, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 47.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  66 Loss:  tensor(0.8303, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  67 Loss:  tensor(0.6963, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  68 Loss:  tensor(0.4139, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 42.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  69 Loss:  tensor(0.3233, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  70 Loss:  tensor(0.2035, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  71 Loss:  tensor(0.1854, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  72 Loss:  tensor(0.1817, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 43.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  73 Loss:  tensor(0.1154, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  74 Loss:  tensor(0.0975, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  75 Loss:  tensor(0.0863, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 44.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  76 Loss:  tensor(0.0732, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  77 Loss:  tensor(0.0595, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 43.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  78 Loss:  tensor(0.0541, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 43.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  79 Loss:  tensor(0.0488, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 44.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  80 Loss:  tensor(0.0413, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 43.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  81 Loss:  tensor(0.0396, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  82 Loss:  tensor(0.0352, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 44.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  83 Loss:  tensor(0.0313, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  84 Loss:  tensor(0.0294, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  85 Loss:  tensor(0.0269, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  86 Loss:  tensor(0.0251, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  87 Loss:  tensor(0.0232, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [00:00<00:00, 43.43it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/amir/Documents/clony/SatViT/classification.ipynb Cell 21\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/amir/Documents/clony/SatViT/classification.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m epoch_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/amir/Documents/clony/SatViT/classification.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m t1 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/amir/Documents/clony/SatViT/classification.ipynb#X26sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m tqdm(train_loader):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/amir/Documents/clony/SatViT/classification.ipynb#X26sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m   img, label \u001b[39m=\u001b[39m batch\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/amir/Documents/clony/SatViT/classification.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m   img, label \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mto(device), label\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/miniconda3/envs/satvit/lib/python3.11/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/satvit/lib/python3.11/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/satvit/lib/python3.11/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/satvit/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;49;00m idx \u001b[39min\u001b[39;49;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/satvit/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/satvit/lib/python3.11/site-packages/torch/utils/data/dataset.py:298\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(idx, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    297\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m idx]]\n\u001b[0;32m--> 298\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices[idx]]\n",
      "\u001b[1;32m/home/amir/Documents/clony/SatViT/classification.ipynb Cell 21\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/amir/Documents/clony/SatViT/classification.ipynb#X26sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/amir/Documents/clony/SatViT/classification.ipynb#X26sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_pickle(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpastis_path, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfile_names[idx]))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/amir/Documents/clony/SatViT/classification.ipynb#X26sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     data[\u001b[39m'\u001b[39m\u001b[39mimg\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39m\u001b[39mimg\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mastype(\u001b[39m'\u001b[39m\u001b[39mfloat32\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/amir/Documents/clony/SatViT/classification.ipynb#X26sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     data[\u001b[39m'\u001b[39m\u001b[39mimg\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(data[\u001b[39m'\u001b[39m\u001b[39mimg\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/amir/Documents/clony/SatViT/classification.ipynb#X26sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     data[\u001b[39m'\u001b[39m\u001b[39mimg\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnormalize(data[\u001b[39m'\u001b[39m\u001b[39mimg\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for epoch in range(epochs):\n",
    "  epoch_loss = 0\n",
    "\n",
    "  t1 = time.time()\n",
    "  for batch in tqdm(train_loader):\n",
    "    img, label = batch\n",
    "    img, label = img.to(device), label.to(device)\n",
    "\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    output = model(img)\n",
    "    \n",
    "    # print(f'Output shape: {output.shape} | Label shape: {label.shape}')\n",
    "    # print('Output: ', output[0], 'Label: ', label[0])\n",
    "\n",
    "    loss = criterion(output, label)\n",
    "    epoch_loss += loss\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "  if epoch % 10 == 0:\n",
    "    torch.save({\n",
    "              'epoch': epoch,\n",
    "              'model_state_dict': model.state_dict(),\n",
    "              'optimizer_state_dict': optimizer.state_dict(),\n",
    "              'loss': loss,\n",
    "              }, f'./weights/cls_epoch_{epoch}.pt')\n",
    "  t2 = time.time()\n",
    "  print('Epoch: ', epoch, 'Loss: ', (epoch_loss/num_samples)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classification(\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (encoder): Transformer(\n",
       "    (layers): ModuleList(\n",
       "      (0-3): 4 x ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Attention(\n",
       "            (to_qkv): Linear(in_features=128, out_features=384, bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (1): Dropout(p=0.5, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): FeedForward(\n",
       "            (net): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.5, inplace=False)\n",
       "              (3): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (4): Dropout(p=0.5, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (projection): Conv3d(10, 128, kernel_size=(1, 3, 3), stride=(1, 3, 3))\n",
       "  (temporal_emb): Linear(in_features=366, out_features=128, bias=True)\n",
       "  (temporal_transformer): Transformer(\n",
       "    (layers): ModuleList(\n",
       "      (0-3): 4 x ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Attention(\n",
       "            (to_qkv): Linear(in_features=128, out_features=384, bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (1): Dropout(p=0.5, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): FeedForward(\n",
       "            (net): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.5, inplace=False)\n",
       "              (3): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (4): Dropout(p=0.5, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (spatial_transformer): Transformer(\n",
       "    (layers): ModuleList(\n",
       "      (0-3): 4 x ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Attention(\n",
       "            (to_qkv): Linear(in_features=128, out_features=384, bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (1): Dropout(p=0.5, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): FeedForward(\n",
       "            (net): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.5, inplace=False)\n",
       "              (3): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (4): Dropout(p=0.5, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (mlp_head): Sequential(\n",
       "    (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = Classification(img_width=9, img_height=9, in_channel=10, patch_size=3, embed_dim=128, max_time=60)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('models/best_epoch_32_val_acc_0.7048091709772124.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "# loss = checkpoint['loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "PASTIS9 = './data/PASTIS9/'\n",
    "PATH = PASTIS9\n",
    "\n",
    "data = PASTIS(PATH)\n",
    "dataset = DataLoader(data, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_loader))\n",
    "x = x.to(device)\n",
    "y = y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 60, 11, 9, 9])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output:  tensor([ 0,  0,  1,  1,  1, 19,  0,  3], device='cuda:0')\n",
      "label:  tensor([19, 19, 19,  1, 19,  0,  1,  0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "x, y = next(iter(train_loader))\n",
    "x = x.to(device)\n",
    "y = y.to(device)\n",
    "\n",
    "print('output: ', torch.argmax(model(x), axis=1))\n",
    "\n",
    "print('label: ', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 4, 8, 1, 1, 3, 3, 2], device='cuda:0')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference on PASTIS24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "PASTIS24 = './data/PASTIS24/'\n",
    "PATH = PASTIS24\n",
    "\n",
    "data = PASTIS(PATH)\n",
    "dataset = DataLoader(data, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(x):\n",
    "    B, T, C, H, W = x.shape\n",
    "    mask = torch.zeros(B, H, W)\n",
    "    x = F.pad(x, (4, 4, 4, 4))\n",
    "\n",
    "    for i in range(24):\n",
    "        for j in range(24):\n",
    "            inp = x[:, :, :, j:j+9, i:i+9]\n",
    "            output = torch.argmax(model(inp), axis=1)\n",
    "            mask[:, j, i] = output\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Prediction: [0, 1, 2, 3, 5, 6, 11, 19]')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = next(iter(dataset))\n",
    "img = img.to(device)\n",
    "output = inference(img)\n",
    "\n",
    "fix, axes = plt.subplots(1,3, figsize=(10,10))\n",
    "axes[0].imshow(get_rgb(img[0][:,:-1,:,:].cpu().numpy()))\n",
    "axes[1].imshow(label[0].numpy(), cmap='inferno')\n",
    "axes[2].imshow(output[0].cpu().numpy(), cmap='inferno')\n",
    "\n",
    "axes[0].set_title('img')\n",
    "axes[1].set_title(f'Label: {label[0].unique().tolist()}')\n",
    "axes[2].set_title(f'Prediction: {output[0].int().cpu().unique().tolist()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 24, 24])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 24, 24])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = torch.flatten(output)\n",
    "label = torch.flatten(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2228732638888889"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(label, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.,  ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 0,  ..., 1, 0, 2])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
