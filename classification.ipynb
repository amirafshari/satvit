{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from torchvision.transforms import ToTensor, Compose\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import os\n",
    "import random\n",
    "import datetime\n",
    "from copy import deepcopy\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from utils.dataset import CutOrPad, get_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PASTIS9 = './data/PASTIS9/'\n",
    "PATH = PASTIS9\n",
    "files = os.listdir(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['img', 'labels', 'doy'])\n",
      "Image:  (46, 10, 9, 9)\n",
      "Labels:  () 1.0\n",
      "DOY:  (46,) [  3  28  43  48  53  58  78  83  88 103 108 123 133 143 153 158 163 168\n",
      " 178 183 188 193 198 203 213 223 233 238 243 248 253 258 263 263 273 273\n",
      " 278 283 288 293 298 308 313 328 343 353]\n"
     ]
    }
   ],
   "source": [
    "file = random.choice(files)\n",
    "data = pd.read_pickle(PATH + file)\n",
    "\n",
    "print(data.keys())\n",
    "print('Image: ', data['img'].shape)\n",
    "print('Labels: ', data['labels'].shape, data['labels'])\n",
    "print('DOY: ', data['doy'].shape, data['doy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PASTIS(Dataset):\n",
    "    def __init__(self, pastis_path):\n",
    "        self.pastis_path = pastis_path\n",
    "\n",
    "        self.file_names = os.listdir(self.pastis_path)[:500]\n",
    "\n",
    "        random.shuffle(self.file_names)\n",
    "\n",
    "        self.to_cutorpad = CutOrPad()\n",
    "        # self.to_tiledates = TileDates(24, 24)\n",
    "        # self.to_unkmask = UnkMask(unk_class=19, ground_truth_target='labels'))\n",
    "\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_names)\n",
    "\n",
    "\n",
    "    def add_date_channel(self, img, doy):\n",
    "        img = torch.cat((img, doy), dim=1)\n",
    "        return img\n",
    "\n",
    "\n",
    "    def normalize(self, img):\n",
    "        C = img.shape[1]\n",
    "        mean = img.mean(dim=(0, 2, 3)).to(torch.float32).reshape(1, C, 1, 1)\n",
    "        std = img.std(dim=(0, 2, 3)).to(torch.float32).reshape(1, C, 1, 1)\n",
    "\n",
    "        img = (img - mean) / std\n",
    "\n",
    "        return img\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = pd.read_pickle(os.path.join(self.pastis_path, self.file_names[idx]))\n",
    "\n",
    "        data['img'] = data['img'].astype('float32')\n",
    "        data['img'] = torch.tensor(data['img'])\n",
    "        data['img'] = self.normalize(data['img'])\n",
    "        T, C, H, W = data['img'].shape\n",
    "\n",
    "        data['labels'] = data['labels'].astype('long')\n",
    "        data['labels'] = torch.tensor(data['labels'])\n",
    "        # data['labels'] = F.one_hot(data['labels'].long(), num_classes=20)\n",
    "\n",
    "        data['doy'] = data['doy'].astype('float32')\n",
    "        data['doy'] = torch.tensor(data['doy'])\n",
    "        data['doy'] = data['doy'].unsqueeze(1).unsqueeze(1).unsqueeze(1)\n",
    "        data['doy'] = data['doy'].repeat(1, 1, H, W)\n",
    "\n",
    "        data['img'] = self.add_date_channel(data['img'], data['doy']) # add DOY to the last channel\n",
    "        del data['doy'] # Delete DOY\n",
    "\n",
    "        data = self.to_cutorpad(data) # Pad to Max Sequence Length\n",
    "        del data['seq_lengths'] # Delete Sequence Length\n",
    "\n",
    "\n",
    "        return data['img'], data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = PASTIS(PATH)\n",
    "data.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set = random_split(data, [400, 100])\n",
    "train_loader = DataLoader(train_set, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAGdCAYAAAAv9mXmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAZzklEQVR4nO3df2xVB/3/8Vd7obcd3HbAKNAv5cdwjlF+DCgQQPfDMfZpgGzGoFu6WMEYnWXAGhephiFBuGCUYADLjyDwzegAo2xzCeMLNYC4VUoZk4qDsTm4Gz86FrwXyrzAvff7xydW6yi3p73vnp7u+UhuYm/O5by8/Hju9MK9aYlEIiEAAFIs3e0BAIDOicAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATXdr7hPF4XOfOnVMgEFBaWlp7nx4A0AaJREJXrlxRXl6e0tNvf43S7oE5d+6c8vPz2/u0AIAUCoVC6t+//22PaffABAIBSdKel/+vunW7o71P32L/Z3Bvtyck1bN3x78CfO+9jr+xct02tye0SNW+/+f2hKROvH/e7QlJRfWp2xOS6h7o5/aEZiUScTVcvdj4Z/nttHtg/vVtsW7d7lD3bt3a+/QtFgh0d3tCUtnZHf8P7+7dO/5Gf4bf7Qkt4kv3uT0hKU9829sD776YltbxXx5vyc91x/9/AQDwJAIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJhoVWDWrl2rQYMGKTMzUxMmTNDhw4dTvQsA4HGOA7Njxw6VlZVp0aJFOnr0qEaNGqXHHntM9fX1FvsAAB7lODArV67Ud77zHc2aNUvDhg3TunXrdMcdd+jXv/61xT4AgEc5Csz169dVW1urKVOm/PsHSE/XlClT9Oabb97yMdFoVJFIpMkNAND5OQrMpUuXFIvF1KdPnyb39+nTRxcuXLjlY4LBoHJychpv+fn5rV8LAPAM879FVl5ernA43HgLhULWpwQAdABdnBx81113yefz6eLFi03uv3jxovr27XvLx/j9fvn93vjMcwBA6ji6gsnIyNDYsWNVVVXVeF88HldVVZUmTpyY8nEAAO9ydAUjSWVlZSopKVFhYaHGjx+vVatWqaGhQbNmzbLYBwDwKMeB+cY3vqGPP/5YL7zwgi5cuKD7779fr7/++mde+AcAfL45DowkzZkzR3PmzEn1FgBAJ8J7kQEATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMBEq95NORV2bK6UP6OrW6dP6suPjnd7QlLDRo11e0JSWXkPuj0hqYFfzHd7Qovcd+ketyckdfeYwW5PSKq+/hO3JyQV+eRTtyc0KxaL6e0T51t0LFcwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYcByYgwcPasaMGcrLy1NaWppefvllg1kAAK9zHJiGhgaNGjVKa9eutdgDAOgkHH9kclFRkYqKiiy2AAA6EceBcSoajSoajTZ+HYlErE8JAOgAzF/kDwaDysnJabzl5+dbnxIA0AGYB6a8vFzhcLjxFgqFrE8JAOgAzL9F5vf75ff7rU8DAOhg+HcwAAATjq9grl69qtOnTzd+/fe//13Hjh1Tz549NWDAgJSOAwB4l+PAHDlyRA8//HDj12VlZZKkkpISbdmyJWXDAADe5jgwDz30kBKJhMUWAEAnwmswAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMGH+iZbNORX6WF27uHb6pNL/+Be3JySV0aWn2xOS6hu95PaEpN6q+ZPbE1qk35393J6Q1P9MmeT2hKR69s1ze0JSZy5ccHtCs65d+1RPffP7LTqWKxgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBggsAAAEw4CkwwGNS4ceMUCASUm5urJ554QidPnrTaBgDwMEeBOXDggEpLS1VdXa29e/fqxo0bmjp1qhoaGqz2AQA8ytFnFr/++utNvt6yZYtyc3NVW1urBx54IKXDAADe5igw/y0cDkuSevZs/rPho9GootFo49eRSKQtpwQAeESrX+SPx+OaP3++Jk+erOHDhzd7XDAYVE5OTuMtPz+/tacEAHhIqwNTWlqquro6bd++/bbHlZeXKxwON95CoVBrTwkA8JBWfYtszpw5eu2113Tw4EH179//tsf6/X75/f5WjQMAeJejwCQSCT377LPatWuX9u/fr8GDB1vtAgB4nKPAlJaWqrKyUq+88ooCgYAuXLggScrJyVFWVpbJQACANzl6DaaiokLhcFgPPfSQ+vXr13jbsWOH1T4AgEc5/hYZAAAtwXuRAQBMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwESrPtEyNSf2q4t7p08qlpbt9oSkMnv3dntCUnXHa92ekNTJk974GO9h93R1e0JS6Tcjbk9IqmdmT7cnJHVHv477e/tqw7UWH8sVDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJhwFpqKiQiNHjlR2drays7M1ceJE7d6922obAMDDHAWmf//+Wr58uWpra3XkyBF95Stf0eOPP66//vWvVvsAAB7l6DOLZ8yY0eTrpUuXqqKiQtXV1SooKEjpMACAtzkKzH+KxWL6zW9+o4aGBk2cOLHZ46LRqKLRaOPXkUjH/8xuAEDbOX6R//jx4+revbv8fr++973vadeuXRo2bFizxweDQeXk5DTe8vPz2zQYAOANjgNz77336tixY/rzn/+sZ555RiUlJTpx4kSzx5eXlyscDjfeQqFQmwYDALzB8bfIMjIy9IUvfEGSNHbsWNXU1OiXv/yl1q9ff8vj/X6//H5/21YCADynzf8OJh6PN3mNBQAAyeEVTHl5uYqKijRgwABduXJFlZWV2r9/v/bs2WO1DwDgUY4CU19fr29+85s6f/68cnJyNHLkSO3Zs0ePPvqo1T4AgEc5CsymTZusdgAAOhneiwwAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmHH+iZcpk+aSu7p0+me53DnR7QlJdMnPcnpDUX9665PaEpG7GMt2e0CKR65fdnpDU2VDY7QlJ+fzn3J6QlC+9q9sTmtVw7dMWH8sVDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJtoUmOXLlystLU3z589P0RwAQGfR6sDU1NRo/fr1GjlyZCr3AAA6iVYF5urVqyouLtbGjRvVo0ePVG8CAHQCrQpMaWmppk2bpilTpiQ9NhqNKhKJNLkBADq/Lk4fsH37dh09elQ1NTUtOj4YDGrx4sWOhwEAvM3RFUwoFNK8efO0bds2ZWZmtugx5eXlCofDjbdQKNSqoQAAb3F0BVNbW6v6+nqNGTOm8b5YLKaDBw9qzZo1ikaj8vl8TR7j9/vl9/tTsxYA4BmOAvPII4/o+PHjTe6bNWuWhg4dqh/+8IefiQsA4PPLUWACgYCGDx/e5L5u3bqpV69en7kfAPD5xr/kBwCYcPy3yP7b/v37UzADANDZcAUDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAE21+N+XWCsfj6hKPu3X6pK41fOL2hKRO/eWE2xOS+ih02e0JSd15V8DtCS3y6Y2O+/vlX+re/8DtCUldCH3g9oSkAj27uz2hWZ/+83qLj+UKBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAE44C85Of/ERpaWlNbkOHDrXaBgDwMMefaFlQUKB9+/b9+wfo4tqHYgIAOjDHdejSpYv69u1rsQUA0Ik4fg3m3XffVV5enu6++24VFxfr7NmzFrsAAB7n6ApmwoQJ2rJli+69916dP39eixcv1pe//GXV1dUpEAjc8jHRaFTRaLTx60gk0rbFAABPcBSYoqKixv89cuRITZgwQQMHDtTOnTv17W9/+5aPCQaDWrx4cdtWAgA8p01/TfnOO+/UF7/4RZ0+fbrZY8rLyxUOhxtvoVCoLacEAHhEmwJz9epVvffee+rXr1+zx/j9fmVnZze5AQA6P0eB+cEPfqADBw7ogw8+0BtvvKGvfvWr8vl8euqpp6z2AQA8ytFrMB9++KGeeuopffLJJ+rdu7e+9KUvqbq6Wr1797baBwDwKEeB2b59u9UOAEAnw3uRAQBMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYcPR2/Sk98U2fusjn1umT8vfMdXtCUueuRd2ekNSFG3G3JyTlS+u4vw7/09UrHf/nOz1w3u0JSV3p3tftCUn5Prrg9oRmXb9+o8XHcgUDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATDgOzEcffaSnn35avXr1UlZWlkaMGKEjR45YbAMAeJijDxy7fPmyJk+erIcffli7d+9W79699e6776pHjx5W+wAAHuUoMCtWrFB+fr42b97ceN/gwYNTPgoA4H2OvkX26quvqrCwUDNnzlRubq5Gjx6tjRs3Wm0DAHiYo8C8//77qqio0D333KM9e/bomWee0dy5c7V169ZmHxONRhWJRJrcAACdn6NvkcXjcRUWFmrZsmWSpNGjR6uurk7r1q1TSUnJLR8TDAa1ePHiti8FAHiKoyuYfv36adiwYU3uu++++3T27NlmH1NeXq5wONx4C4VCrVsKAPAUR1cwkydP1smTJ5vcd+rUKQ0cOLDZx/j9fvn9/tatAwB4lqMrmOeee07V1dVatmyZTp8+rcrKSm3YsEGlpaVW+wAAHuUoMOPGjdOuXbv00ksvafjw4VqyZIlWrVql4uJiq30AAI9y9C0ySZo+fbqmT59usQUA0InwXmQAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYcv11/qvTwR9W1a8yt0yeV3f2y2xOSeqf6HbcnJHX55N/cnpBUZo8ctye0SMID/zkY/uS62xOSutYQcXtCUr70m25PaNaNGzdafKwHfskCALyIwAAATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATjgIzaNAgpaWlfeZWWlpqtQ8A4FGOPtGypqZGsdi/P4Wyrq5Ojz76qGbOnJnyYQAAb3MUmN69ezf5evny5RoyZIgefPDBlI4CAHifo8D8p+vXr+vFF19UWVmZ0tLSmj0uGo0qGo02fh2JdPzPwwYAtF2rX+R/+eWX9Y9//EPf+ta3bntcMBhUTk5O4y0/P7+1pwQAeEirA7Np0yYVFRUpLy/vtseVl5crHA433kKhUGtPCQDwkFZ9i+zMmTPat2+ffve73yU91u/3y+/3t+Y0AAAPa9UVzObNm5Wbm6tp06aleg8AoJNwHJh4PK7NmzerpKREXbq0+u8IAAA6OceB2bdvn86ePavZs2db7AEAdBKOL0GmTp2qRCJhsQUA0InwXmQAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAw4doHuvTqna2MjK5unT6pa/E0tyckdel81O0JSfUM5Lg9IambHf9plCQ1XPmH2xOSOh/u+E9mwnfJ7QlJpfk67u+bWOxmi4/lCgYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABOOAhOLxbRw4UINHjxYWVlZGjJkiJYsWaJEImG1DwDgUY4+0XLFihWqqKjQ1q1bVVBQoCNHjmjWrFnKycnR3LlzrTYCADzIUWDeeOMNPf7445o2bZokadCgQXrppZd0+PBhk3EAAO9y9C2ySZMmqaqqSqdOnZIkvf322zp06JCKioqafUw0GlUkEmlyAwB0fo6uYBYsWKBIJKKhQ4fK5/MpFotp6dKlKi4ubvYxwWBQixcvbvNQAIC3OLqC2blzp7Zt26bKykodPXpUW7du1c9//nNt3bq12ceUl5crHA433kKhUJtHAwA6PkdXMM8//7wWLFigJ598UpI0YsQInTlzRsFgUCUlJbd8jN/vl9/vb/tSAICnOLqCuXbtmtLTmz7E5/MpHo+ndBQAwPscXcHMmDFDS5cu1YABA1RQUKC33npLK1eu1OzZs632AQA8ylFgVq9erYULF+r73/++6uvrlZeXp+9+97t64YUXrPYBADzKUWACgYBWrVqlVatWGc0BAHQWvBcZAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGDC0ZtdpkIikZAkXb9+o71P7cg//xl1e0JSN2527OdQkm7Gbro9IambMbcXtEws3vGHxmIdf2PC7QEtkKaO+/vmXz/H//qz/HbSEi05KoU+/PBD5efnt+cpAQApFgqF1L9//9se0+6BicfjOnfunAKBgNLS0tr840UiEeXn5ysUCik7OzsFCz+feB5Tg+cxdXguUyPVz2MikdCVK1eUl5f3mU84/m/t/i2y9PT0pNVrjezsbH4RpgDPY2rwPKYOz2VqpPJ5zMnJadFxvMgPADBBYAAAJjwfGL/fr0WLFsnv97s9xdN4HlOD5zF1eC5Tw83nsd1f5AcAfD54/goGANAxERgAgAkCAwAwQWAAACY8H5i1a9dq0KBByszM1IQJE3T48GG3J3lKMBjUuHHjFAgElJubqyeeeEInT550e5bnLV++XGlpaZo/f77bUzzno48+0tNPP61evXopKytLI0aM0JEjR9ye5SmxWEwLFy7U4MGDlZWVpSFDhmjJkiUtev+wVPJ0YHbs2KGysjItWrRIR48e1ahRo/TYY4+pvr7e7WmeceDAAZWWlqq6ulp79+7VjRs3NHXqVDU0NLg9zbNqamq0fv16jRw50u0pnnP58mVNnjxZXbt21e7du3XixAn94he/UI8ePdye5ikrVqxQRUWF1qxZo7/97W9asWKFfvazn2n16tXtusPTf015woQJGjdunNasWSPpf9/nLD8/X88++6wWLFjg8jpv+vjjj5Wbm6sDBw7ogQcecHuO51y9elVjxozRr371K/30pz/V/fffr1WrVrk9yzMWLFigP/3pT/rjH//o9hRPmz59uvr06aNNmzY13ve1r31NWVlZevHFF9tth2evYK5fv67a2lpNmTKl8b709HRNmTJFb775povLvC0cDkuSevbs6fISbyotLdW0adOa/LpEy7366qsqLCzUzJkzlZubq9GjR2vjxo1uz/KcSZMmqaqqSqdOnZIkvf322zp06JCKioradUe7v9llqly6dEmxWEx9+vRpcn+fPn30zjvvuLTK2+LxuObPn6/Jkydr+PDhbs/xnO3bt+vo0aOqqalxe4pnvf/++6qoqFBZWZl+9KMfqaamRnPnzlVGRoZKSkrcnucZCxYsUCQS0dChQ+Xz+RSLxbR06VIVFxe36w7PBgapV1paqrq6Oh06dMjtKZ4TCoU0b9487d27V5mZmW7P8ax4PK7CwkItW7ZMkjR69GjV1dVp3bp1BMaBnTt3atu2baqsrFRBQYGOHTum+fPnKy8vr12fR88G5q677pLP59PFixeb3H/x4kX17dvXpVXeNWfOHL322ms6ePCgyccpdHa1tbWqr6/XmDFjGu+LxWI6ePCg1qxZo2g0Kp/P5+JCb+jXr5+GDRvW5L777rtPv/3tb11a5E3PP/+8FixYoCeffFKSNGLECJ05c0bBYLBdA+PZ12AyMjI0duxYVVVVNd4Xj8dVVVWliRMnurjMWxKJhObMmaNdu3bpD3/4gwYPHuz2JE965JFHdPz4cR07dqzxVlhYqOLiYh07doy4tNDkyZM/89fkT506pYEDB7q0yJuuXbv2mQ8D8/l8isfj7brDs1cwklRWVqaSkhIVFhZq/PjxWrVqlRoaGjRr1iy3p3lGaWmpKisr9corrygQCOjChQuS/vcDhbKyslxe5x2BQOAzr1t169ZNvXr14vUsB5577jlNmjRJy5Yt09e//nUdPnxYGzZs0IYNG9ye5ikzZszQ0qVLNWDAABUUFOitt97SypUrNXv27PYdkvC41atXJwYMGJDIyMhIjB8/PlFdXe32JE+RdMvb5s2b3Z7meQ8++GBi3rx5bs/wnN///veJ4cOHJ/x+f2Lo0KGJDRs2uD3JcyKRSGLevHmJAQMGJDIzMxN333134sc//nEiGo226w5P/zsYAEDH5dnXYAAAHRuBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYOL/AyhvFegaVW7tAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = next(iter(train_loader))\n",
    "plt.imshow(get_rgb(img[0][:,:-1,:,:].numpy()))\n",
    "print(label[0].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, einsum\n",
    "from einops import rearrange\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "\n",
    "\n",
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, dim, fn):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x, **kwargs):\n",
    "        return self.fn(self.norm(x), **kwargs)\n",
    "\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, dropout=0.):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, heads=8, dim_head=64, dropout=0.):\n",
    "        super().__init__()\n",
    "        inner_dim = dim_head * heads\n",
    "        project_out = not (heads == 1 and dim_head == dim)\n",
    "\n",
    "        self.heads = heads\n",
    "        self.scale = dim_head ** -0.5\n",
    "\n",
    "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias=False)\n",
    "\n",
    "        self.to_out = nn.Sequential(\n",
    "            nn.Linear(inner_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        ) if project_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        b, n, _, h = *x.shape, self.heads\n",
    "        qkv = self.to_qkv(x).chunk(3, dim=-1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h=h), qkv)\n",
    "        # print(q.shape, k.shape, v.shape)\n",
    "        dots = einsum('b h i d, b h j d -> b h i j', q, k) * self.scale\n",
    "\n",
    "        attn = dots.softmax(dim=-1)\n",
    "\n",
    "        out = einsum('b h i j, b h j d -> b h i d', attn, v)\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "        out = self.to_out(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout=0.):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([])\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                PreNorm(dim, Attention(dim, heads=heads, dim_head=dim_head, dropout=dropout)),\n",
    "                PreNorm(dim, FeedForward(dim, mlp_dim, dropout=dropout))\n",
    "            ]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for attn, ff in self.layers:\n",
    "            x = attn(x) + x\n",
    "            x = ff(x) + x\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classification(nn.Module):\n",
    "    def __init__(self, img_height=9, img_width=9, in_channel=10,\n",
    "                       patch_size=3, embed_dim=128, max_time=60,\n",
    "                       num_classes=20, num_head=4, dim_feedforward=2048,\n",
    "                       num_layers=4\n",
    "                ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.H = img_height\n",
    "        self.W = img_width\n",
    "        self.P = patch_size\n",
    "        self.C = in_channel\n",
    "        self.d = embed_dim\n",
    "        self.T = max_time\n",
    "        self.K = num_classes\n",
    "\n",
    "        self.d_model = self.d\n",
    "        self.num_head = num_head\n",
    "        self.dim_feedforward = self.d\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.N = int(self.H * self.W // self.P**2)\n",
    "        self.nh = int(self.H / self.P)\n",
    "        self.nw = int(self.W / self.P)\n",
    "\n",
    "\n",
    "        '''\n",
    "        PARAMETERS\n",
    "        '''\n",
    "        # Transformer Encoder\n",
    "\n",
    "        # PyTorch Encoder\n",
    "        # self.encoderLayer = nn.TransformerEncoderLayer(d_model=self.d_model, nhead=self.num_head, dim_feedforward=self.dim_feedforward)\n",
    "        # self.encoder = nn.TransformerEncoder(self.encoderLayer, num_layers=self.num_layers)\n",
    "\n",
    "        # DeepSat Encoder\n",
    "        self.encoder = Transformer(self.d, self.num_layers, self.num_head, 32, self.d*4)\n",
    "\n",
    "\n",
    "        # torchvision Encoder\n",
    "        # self.encoder = Encoder(seq_length=self.N, num_heads=4, num_layers=4, hidden_dim=self.d, mlp_dim=self.d*4, dropout=0., attention_dropout=0.)\n",
    "\n",
    "\n",
    "        # Patches\n",
    "        self.projection = nn.Conv3d(self.C, self.d, kernel_size=(1, self.P, self.P), stride=(1, self.P, self.P))\n",
    "        '''\n",
    "        def __init__():\n",
    "            self.linear = nn.Linear(self.C*self.P**2, self.d)\n",
    "        def forward():\n",
    "            x = x.view(B, T, H // P, W // P, C*P**2)\n",
    "            x = self.linear(x)\n",
    "        '''\n",
    "\n",
    "        # Temporal\n",
    "        self.temporal_emb = nn.Linear(366, self.d)\n",
    "        self.temporal_cls_token = nn.Parameter(torch.randn(1, self.N, self.K, self.d)) # (N, K, d)\n",
    "        self.temporal_transformer = self.encoder\n",
    "\n",
    "        # Spatial\n",
    "        self.spatial_emb = nn.Parameter(torch.randn(1, self.N, self.d)) # (1, N, d)\n",
    "        self.spatial_cls_token = nn.Parameter(torch.randn(1, self.K, self.d)) # (1, K, d)\n",
    "        self.spatial_transformer = self.encoder\n",
    "\n",
    "        # Segmentation Head\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LayerNorm(self.d),\n",
    "            nn.Linear(self.d, 1)\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Tekenization\n",
    "\n",
    "        Convert the images to a sequence of patches\n",
    "        '''\n",
    "        x_sits = x[:, :, :-1, :, :] # (B, T, C, H, W) -- > Exclude DOY Channel\n",
    "        B, T, C, H, W = x_sits.shape # (B, T, C, H, W)\n",
    "        x_sits = x_sits.reshape(B, C, T, H, W) # (B, C, T, H, W)\n",
    "        x_sits = self.projection(x_sits) # (B, d, T, nw, nh)\n",
    "        x_sits = x_sits.reshape(B, self.d, T, self.nh*self.nw) # (B, d, T, N)\n",
    "        # x_sits = x_sits + self.pos_emb # (B, d, T, N)  we dont add pos embedding here, cuz we need the pure data for the temporal encoder\n",
    "        x_sits = x_sits.permute(0,3,2,1) # (B, N, T, d)\n",
    "\n",
    "\n",
    "\n",
    "        '''\n",
    "        Temporal Encoding\n",
    "\n",
    "        (DOY -> One-Hot -> Projection)\n",
    "        '''\n",
    "        xt = x[:, :, -1, 0, 0] # (B, T, C, H, W) in the last channel lies the DOY feature\n",
    "        xt = F.one_hot(xt.to(torch.int64), num_classes=366).to(torch.float32) # (B, T, 366)\n",
    "        Pt = self.temporal_emb(xt) # (B, T, d) (DOY, one-hot encoded to represent the DOY feature and then encoded to d dimensions)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        '''\n",
    "        Temporal Encoder: cat(Z+Pt)\n",
    "\n",
    "        add temporal embeddings (N*K) to the Time Series patches (T)\n",
    "        '''\n",
    "        x = x_sits + Pt.unsqueeze(1) # (B, N, T, d)\n",
    "        temporal_cls_token = self.temporal_cls_token # (1, N, K, d)\n",
    "        temporal_cls_token = temporal_cls_token.repeat(B, 1, 1, 1) # (B, N, K, d)\n",
    "        temporal_cls_token = temporal_cls_token.reshape(B*self.N, self.K, self.d) # (B*N, K, d)\n",
    "        x = x.reshape(B*self.N, T, self.d) # (B*N, T, d)\n",
    "        # Temporal Tokens (N*K)\n",
    "        x = torch.cat([temporal_cls_token, x], dim=1) # (B*N, K+T, d)\n",
    "        # Temporal Transformer\n",
    "        x = self.temporal_transformer(x) # (B*N, K+T, d)\n",
    "        x = x.reshape(B, self.N, self.K + T, self.d) # (B, N, K+T, d)\n",
    "        x = x[:,:,:self.K,:] # (B, N, K, d)\n",
    "        x = x.permute(0, 2, 1, 3) # (B, K, N, d)\n",
    "        x = x.reshape(B*(self.K), self.N, self.d) # (B*K, N, d)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        '''\n",
    "        Spatial Encoding\n",
    "        '''\n",
    "        Ps = self.spatial_emb # (1, N, d)\n",
    "        x = x + Ps # (B*K, N, d)\n",
    "        # For Classification Only\n",
    "        spatial_cls_token = self.spatial_cls_token # (1, K, d)\n",
    "        spatial_cls_token = spatial_cls_token.unsqueeze(2) # (1, K, 1, d)\n",
    "        spatial_cls_token = spatial_cls_token.repeat(B, 1, 1, 1) # (B, K, 1, d)\n",
    "        spatial_cls_token = spatial_cls_token.reshape(B*self.K, 1, self.d) # (B*K, 1, d)\n",
    "        x = torch.cat([spatial_cls_token, x], dim=1) # (B*K, 1+N, d)\n",
    "        x = self.spatial_transformer(x) # (B*K, N+1, d)\n",
    "\n",
    "\n",
    "\n",
    "        '''\n",
    "        Classification Head\n",
    "        '''\n",
    "        classes = x[:,0,:] # (B*K, d)\n",
    "        classes = classes.reshape(B, self.K, self.d) # (B, K, d)\n",
    "        \n",
    "        x = self.mlp_head(classes) # (B, K, 1)\n",
    "        x = x.reshape(B, self.K) # (B, K)\n",
    "\n",
    "\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Credits to  github.com/clcarwin/focal_loss_pytorch\n",
    "    \"\"\"\n",
    "    def __init__(self, gamma=8, alpha=torch.ones(20), reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        if isinstance(alpha, (float, int)): self.alpha = torch.Tensor([alpha, 1 - alpha])\n",
    "        if isinstance(alpha, list): self.alpha = torch.Tensor(alpha)\n",
    "        self.reduction = reduction\n",
    "        \n",
    "    def forward(self, input, target):\n",
    "        if input.dim() > 2:\n",
    "            input = input.view(input.size(0), input.size(1), -1)  # N,C,H,W => N,C,H*W\n",
    "            input = input.transpose(1, 2)  # N,C,H*W => N,H*W,C\n",
    "            input = input.contiguous().view(-1, input.size(2))  # N,H*W,C => N*H*W,C\n",
    "        target = target.view(-1, 1)\n",
    "\n",
    "        logpt = F.log_softmax(input, dim=1)\n",
    "        logpt = logpt.gather(1, target)\n",
    "        logpt = logpt.view(-1)\n",
    "        pt = Variable(logpt.data.exp())\n",
    "\n",
    "        if self.alpha is not None:\n",
    "            if self.alpha.type() != input.data.type():\n",
    "                self.alpha = self.alpha.type_as(input.data)\n",
    "            at = self.alpha.gather(0, target.data.view(-1))\n",
    "            logpt = logpt * Variable(at)\n",
    "\n",
    "        loss = -1 * (1 - pt) ** self.gamma * logpt\n",
    "        if self.reduction is None:\n",
    "            return loss\n",
    "        elif self.reduction == \"mean\":\n",
    "            return loss.mean()\n",
    "        elif self.reduction == \"sum\":\n",
    "            return loss.sum()\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"FocalLoss: reduction parameter not in list of acceptable values [\\\"mean\\\", \\\"sum\\\", None]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Parameters:  877569\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Classification(\n",
       "  (encoder): Transformer(\n",
       "    (layers): ModuleList(\n",
       "      (0-3): 4 x ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Attention(\n",
       "            (to_qkv): Linear(in_features=128, out_features=384, bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): FeedForward(\n",
       "            (net): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (4): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (projection): Conv3d(10, 128, kernel_size=(1, 3, 3), stride=(1, 3, 3))\n",
       "  (temporal_emb): Linear(in_features=366, out_features=128, bias=True)\n",
       "  (temporal_transformer): Transformer(\n",
       "    (layers): ModuleList(\n",
       "      (0-3): 4 x ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Attention(\n",
       "            (to_qkv): Linear(in_features=128, out_features=384, bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): FeedForward(\n",
       "            (net): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (4): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (spatial_transformer): Transformer(\n",
       "    (layers): ModuleList(\n",
       "      (0-3): 4 x ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Attention(\n",
       "            (to_qkv): Linear(in_features=128, out_features=384, bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): FeedForward(\n",
       "            (net): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (4): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (mlp_head): Sequential(\n",
       "    (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Data\n",
    "batch_size = 8\n",
    "\n",
    "# Model\n",
    "model = Classification(img_width=9, img_height=9, in_channel=10, patch_size=3, embed_dim=128, max_time=60, num_head=4, num_layers=4, num_classes=20)\n",
    "model.to(device)\n",
    "\n",
    "num_samples = train_loader.__len__()*batch_size\n",
    "\n",
    "num_params = sum([p.numel() for p in model.parameters() if p.requires_grad == True])\n",
    "print('Number of Parameters: ', num_params)\n",
    "\n",
    "# Loss\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion = FocalLoss()\n",
    "# criterion = nn.MSELoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "# optimizer = optim.AdamW(model.parameters(), lr=0.01)\n",
    "epochs = 200\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 25.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 Loss:  tensor(12.9140, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 Loss:  tensor(10.8758, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 45.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2 Loss:  tensor(10.8166, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 43.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3 Loss:  tensor(10.4740, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4 Loss:  tensor(10.5409, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5 Loss:  tensor(10.1680, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 47.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  6 Loss:  tensor(10.1514, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 47.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  7 Loss:  tensor(9.9712, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  8 Loss:  tensor(10.0372, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 45.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  9 Loss:  tensor(10.1721, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 44.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  10 Loss:  tensor(10.0184, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 44.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  11 Loss:  tensor(10.2046, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 44.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  12 Loss:  tensor(10.0178, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 45.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  13 Loss:  tensor(9.9785, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 44.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  14 Loss:  tensor(10.0218, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 44.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  15 Loss:  tensor(10.0331, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 38.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  16 Loss:  tensor(9.9843, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 40.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  17 Loss:  tensor(10.0402, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 44.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  18 Loss:  tensor(9.9938, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 45.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  19 Loss:  tensor(10.0379, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  20 Loss:  tensor(10.0594, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  21 Loss:  tensor(9.9281, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  22 Loss:  tensor(9.9960, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  23 Loss:  tensor(9.8742, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 44.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  24 Loss:  tensor(9.7996, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 40.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  25 Loss:  tensor(10.1176, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 42.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  26 Loss:  tensor(9.8890, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 42.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  27 Loss:  tensor(9.9468, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 45.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  28 Loss:  tensor(9.8969, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 45.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  29 Loss:  tensor(9.8680, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 42.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  30 Loss:  tensor(9.7558, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 43.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  31 Loss:  tensor(9.7963, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 45.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  32 Loss:  tensor(9.6681, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 44.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  33 Loss:  tensor(9.3855, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 45.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  34 Loss:  tensor(9.5058, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 45.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  35 Loss:  tensor(9.3339, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 43.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  36 Loss:  tensor(9.1022, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  37 Loss:  tensor(8.9878, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 44.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  38 Loss:  tensor(8.8490, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 45.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  39 Loss:  tensor(8.5934, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 45.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  40 Loss:  tensor(8.2525, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  41 Loss:  tensor(8.4291, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  42 Loss:  tensor(7.9110, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  43 Loss:  tensor(7.5029, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 42.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  44 Loss:  tensor(7.2679, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 45.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  45 Loss:  tensor(7.2742, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  46 Loss:  tensor(6.7666, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  47 Loss:  tensor(6.5566, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  48 Loss:  tensor(5.8860, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  49 Loss:  tensor(5.8250, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 37.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  50 Loss:  tensor(5.9040, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  51 Loss:  tensor(4.8997, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 42.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  52 Loss:  tensor(4.4308, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  53 Loss:  tensor(3.9613, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  54 Loss:  tensor(2.9745, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  55 Loss:  tensor(3.2704, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  56 Loss:  tensor(3.5592, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 44.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  57 Loss:  tensor(2.4523, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  58 Loss:  tensor(2.2135, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 47.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  59 Loss:  tensor(2.2119, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  60 Loss:  tensor(1.5775, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  61 Loss:  tensor(2.6455, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 45.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  62 Loss:  tensor(3.1356, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  63 Loss:  tensor(1.8422, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 43.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  64 Loss:  tensor(1.0591, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  65 Loss:  tensor(0.9438, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 47.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  66 Loss:  tensor(0.8303, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  67 Loss:  tensor(0.6963, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  68 Loss:  tensor(0.4139, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 42.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  69 Loss:  tensor(0.3233, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  70 Loss:  tensor(0.2035, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  71 Loss:  tensor(0.1854, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  72 Loss:  tensor(0.1817, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 43.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  73 Loss:  tensor(0.1154, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  74 Loss:  tensor(0.0975, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  75 Loss:  tensor(0.0863, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 44.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  76 Loss:  tensor(0.0732, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  77 Loss:  tensor(0.0595, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 43.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  78 Loss:  tensor(0.0541, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 43.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  79 Loss:  tensor(0.0488, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 44.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  80 Loss:  tensor(0.0413, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 43.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  81 Loss:  tensor(0.0396, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  82 Loss:  tensor(0.0352, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 44.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  83 Loss:  tensor(0.0313, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  84 Loss:  tensor(0.0294, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  85 Loss:  tensor(0.0269, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  86 Loss:  tensor(0.0251, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  87 Loss:  tensor(0.0232, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [00:00<00:00, 43.43it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/amir/Documents/clony/SatViT/classification.ipynb Cell 21\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/amir/Documents/clony/SatViT/classification.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m epoch_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/amir/Documents/clony/SatViT/classification.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m t1 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/amir/Documents/clony/SatViT/classification.ipynb#X26sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m tqdm(train_loader):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/amir/Documents/clony/SatViT/classification.ipynb#X26sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m   img, label \u001b[39m=\u001b[39m batch\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/amir/Documents/clony/SatViT/classification.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m   img, label \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mto(device), label\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/miniconda3/envs/satvit/lib/python3.11/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/satvit/lib/python3.11/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/satvit/lib/python3.11/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/satvit/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;49;00m idx \u001b[39min\u001b[39;49;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/satvit/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/satvit/lib/python3.11/site-packages/torch/utils/data/dataset.py:298\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(idx, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    297\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m idx]]\n\u001b[0;32m--> 298\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices[idx]]\n",
      "\u001b[1;32m/home/amir/Documents/clony/SatViT/classification.ipynb Cell 21\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/amir/Documents/clony/SatViT/classification.ipynb#X26sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/amir/Documents/clony/SatViT/classification.ipynb#X26sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_pickle(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpastis_path, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfile_names[idx]))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/amir/Documents/clony/SatViT/classification.ipynb#X26sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     data[\u001b[39m'\u001b[39m\u001b[39mimg\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39m\u001b[39mimg\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mastype(\u001b[39m'\u001b[39m\u001b[39mfloat32\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/amir/Documents/clony/SatViT/classification.ipynb#X26sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     data[\u001b[39m'\u001b[39m\u001b[39mimg\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(data[\u001b[39m'\u001b[39m\u001b[39mimg\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/amir/Documents/clony/SatViT/classification.ipynb#X26sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     data[\u001b[39m'\u001b[39m\u001b[39mimg\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnormalize(data[\u001b[39m'\u001b[39m\u001b[39mimg\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for epoch in range(epochs):\n",
    "  epoch_loss = 0\n",
    "\n",
    "  t1 = time.time()\n",
    "  for batch in tqdm(train_loader):\n",
    "    img, label = batch\n",
    "    img, label = img.to(device), label.to(device)\n",
    "\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    output = model(img)\n",
    "    \n",
    "    # print(f'Output shape: {output.shape} | Label shape: {label.shape}')\n",
    "    # print('Output: ', output[0], 'Label: ', label[0])\n",
    "\n",
    "    loss = criterion(output, label)\n",
    "    epoch_loss += loss\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "  if epoch % 10 == 0:\n",
    "    torch.save({\n",
    "              'epoch': epoch,\n",
    "              'model_state_dict': model.state_dict(),\n",
    "              'optimizer_state_dict': optimizer.state_dict(),\n",
    "              'loss': loss,\n",
    "              }, f'./weights/cls_epoch_{epoch}.pt')\n",
    "  t2 = time.time()\n",
    "  print('Epoch: ', epoch, 'Loss: ', (epoch_loss/num_samples)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = Classification(img_width=9, img_height=9, in_channel=10, patch_size=3, embed_dim=128, max_time=60)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('weights/epoch_60.pt')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PASTIS9 = './data/PASTIS9/'\n",
    "PATH = PASTIS9\n",
    "\n",
    "data = PASTIS(PATH)\n",
    "dataset = DataLoader(data, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_loader))\n",
    "x = x.to(device)\n",
    "y = y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 60, 11, 9, 9])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1, 3, 0, 1, 1, 0], device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(model(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1, 3, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference on PASTIS24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "PASTIS24 = './data/PASTIS24/'\n",
    "PATH = PASTIS24\n",
    "\n",
    "data = PASTIS(PATH)\n",
    "dataset = DataLoader(data, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(x):\n",
    "    B, T, C, H, W = x.shape\n",
    "    mask = torch.zeros(B, H, W)\n",
    "    x = F.pad(x, (4, 4, 4, 4))\n",
    "\n",
    "    for i in range(24):\n",
    "        for j in range(24):\n",
    "            inp = x[:, :, :, j:j+9, i:i+9]\n",
    "            output = torch.argmax(model(inp), axis=1)\n",
    "            mask[:, j, i] = output\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Prediction: [0, 1, 2, 4, 5]')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzYAAAElCAYAAAA2knddAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABCcklEQVR4nO3de3xU9bX///ckmUzuCQESEgk3iyJesAWhVFFQBNFSUVuligJfi1bRVqnaelpEqy0q1dIqBU+tonip5VS0Xo6KGEA5gBVRixUKGgQKgRDIPZkkM/v3B79MiUn4fJJMMrOT1/PxyOOhM4u1V/ZMVmZlXz4ex3EcAQAAAICLxUS6AAAAAABoLwYbAAAAAK7HYAMAAADA9RhsAAAAALgegw0AAAAA12OwAQAAAOB6DDYAAAAAXI/BBgAAAIDrMdgAAAAAcD0GGxgtXbpUHo9HO3fujHQpAI6yc+dOeTwe/eY3vwlbztWrV8vj8Wj16tVt+vcDBgyQx+ORx+PRTTfdFLa60NTChQtD+9rj8ejgwYORLglRYsCAAZoxY0bo/9v7c90cj8eju+++O2z52uvon4Vw9kS0XUlJSae/Lgw2ANCJGv5Q8MEHH0S6lA4zZswYLVu2TNOnT2/y3J/+9CeddNJJSkhI0ODBg/XII4+0a1svvPCCpk2bpsGDB8vj8Wjs2LHtyhcMBrV06VJ95zvfUV5enpKTk3XKKafovvvuU01NTZvz7tu3Tz/72c80btw4paamHvNDZl1dne655x4NGjRIPp9PgwYN0n333af6+vpGcRdccIGWLVumSy65pM11IfwafsYbvhISEnTCCSfopptu0v79+yNdXqu8/vrrUTW8mFxyySVatmyZLrrookaPB4NBPfjggxo4cKASEhJ02mmn6fnnn2/XthYvXqzvfe976tevnzweT6NBsi2qqqq0aNEiTZgwQTk5OUpNTdXXv/51LV68WIFAoF25j3b++ee3+w9PX32PH/1VWFgYiktOTtayZcv029/+NhylW4nrtC3Bta6++mpNnTpVPp8v0qUAcIFBgwZp2rRpTR5/7LHH9MMf/lCXXXaZ5syZo3fffVc/+tGPVFVVpZ/+9Kdt2tbixYu1adMmnXHGGSouLm5v6aqqqtLMmTP1zW9+Uz/84Q+VlZWl9evXa968eVq1apXeeecdeTyeVufdtm2bHnjgAQ0ePFinnnqq1q9f32LstGnTtHz5cv2///f/NGLECG3YsEFz587Vrl279N///d+huCFDhmjIkCHasWOHVqxY0abvFx3nl7/8pQYOHKiamhq99957Wrx4sV5//XVt2bJFSUlJnVrL2WefrerqasXHx7fq373++utatGhRs8NNdXW14uKi62Pkaaed1mzv+fnPf677779fs2bN0hlnnKGXX35ZV155pTwej6ZOndqmbT3wwAMqLy/XyJEjtW/fvvaWri+++EI333yzzjvvPM2ZM0dpaWl68803deONN2rDhg166qmn2r2NF1988Zi9p7Ua3uNHy8jICP231+vVtGnTtHPnTt16661h2+4xOQCATvPkk086kpy///3v7c5VUFDgSHIWLFgQhsqOyM/PdyQ5+fn5bfr3/fv3d6ZPn97k8aqqKqdnz57ORRdd1Ojxq666yklOTnYOHTrUpu3t2rXLCQQCjuM4zsknn+ycc845bcrTwO/3O+vWrWvy+D333ONIclauXNmmvGVlZU5xcbHjOI6zfPnyFvfx+++/70hy5s6d2+jxn/zkJ47H43E+/vjjJv9m3rx5jiSnqKioTbUhvFr6GZ8zZ44jyXnuueda/LcVFRVhqaGln8PWmj17tuOWj4qSnHnz5jV5fM+ePY7X63Vmz54deiwYDDpjxoxx+vbt69TX17dpezt37nSCwaDjOI6TnJzc7v1dVFTkbNmypcnjM2fOdCQ527dvb1f+6upqZ8CAAc4vf/lLR1Kj/dFarf091hG/q1rCqWgw+uo1NgMGDNC3v/1trV69WiNGjFBiYqJOPfXU0GkVL774ok499VQlJCRo+PDh2rx5c5Ocy5cv19ChQ5WQkKBTTjlFK1as0IwZMzRgwIDO+8aAKFVbW6u77rpLw4cPV3p6upKTkzVmzBjl5+e3+G9++9vfqn///kpMTNQ555yjLVu2NInZunWrvvvd7yozM1MJCQkaMWKE/va3vxnrqaqq0tatW9t1DUd+fr6Ki4t14403Nnp89uzZqqys1GuvvdamvHl5eYqJCd+vsvj4eH3rW99q8njD6V6fffZZm/KmpqYqMzPTGPfuu+9KUpO/Ik+dOlWO4+iFF15o0/YReeeee64kqaCgQJI0Y8YMpaSk6PPPP9eFF16o1NRUXXXVVZKOnDq1cOFCnXzyyUpISFB2drauv/56HT58uFFOx3F03333qW/fvkpKStK4ceP06aefNtl2S9fYbNy4URdeeKF69Oih5ORknXbaafrd734Xqm/RokWSGl+/0qC5a2w2b96sSZMmKS0tTSkpKTrvvPO0YcOGRjENnynWrVunOXPmqHfv3kpOTtYll1yioqKiRrGlpaXaunWrSktLbXZxs15++WXV1dU16j0ej0c33HCD9uzZ0+YjGP3792/T0duW9OrVSyeffHKTx9vbexo8+OCDCgaDuu2229qV56vKy8vDeqpcezHYoE127NihK6+8UpMnT9b8+fN1+PBhTZ48Wc8++6xuvfVWTZs2Tffcc48+//xzXX755QoGg6F/+9prr+mKK66Q1+vV/Pnzdemll+raa6/Vpk2bIvgdAdGjrKxMjz/+uMaOHasHHnhAd999t4qKijRx4kR99NFHTeKffvpp/f73v9fs2bN15513asuWLTr33HMbnc//6aef6pvf/KY+++wz/exnP9NDDz2k5ORkTZkyxXga0/vvv6+TTjpJjz76aJu/p4Y/cIwYMaLR48OHD1dMTEyzfwCJJg3njffq1atDt+P3+yVJiYmJjR5vOHWJPulen3/+uSSpZ8+eocfq6+s1ceJEZWVl6Te/+Y0uu+wySdL111+v22+/XWeeeaZ+97vfaebMmXr22Wc1ceJE1dXVhf79XXfdpblz52rYsGFasGCBBg0apAkTJqiystJYz8qVK3X22Wfrn//8p3784x/roYce0rhx4/Tqq6+Gajj//PMlScuWLQt9teTTTz/VmDFj9PHHH+uOO+7Q3LlzVVBQoLFjx2rjxo1N4m+++WZ9/PHHmjdvnm644Qa98sorTa77WLFihU466aR2nWq5efNmJScn66STTmr0+MiRI0PPR7Nw9J5du3bp/vvv1wMPPNCkt7THuHHjlJaWpqSkJH3nO9/R9u3bw5a7raLr5Ei4xrZt2/R///d/Gj16tCRp6NChmjhxombNmqWtW7eqX79+kqQePXro+uuv19q1a0MX9d5555067rjjtG7dOqWkpEiSzjvvPI0dO1b9+/ePyPcDRJMePXpo586djc6HnzVrloYMGaJHHnlEf/rTnxrF79ixQ9u3b9dxxx0n6chF5aNGjdIDDzyghx9+WJL04x//WP369dPf//730PVyN954o8466yz99Kc/7fAL0Pft26fY2FhlZWU1ejw+Pl49e/bU3r17O3T77fXggw8qLS1NkyZN6tDtnHjiiZKkdevWNTp3veFIzr///e8O3T7Cp7S0VAcPHlRNTY3WrVunX/7yl0pMTNS3v/3tUIzf79f3vvc9zZ8/P/TYe++9p8cff1zPPvusrrzyytDj48aN0wUXXKDly5fryiuvVFFRkR588EFddNFFeuWVV0JHD37+85/r17/+9TFrCwQCuv7665WTk6OPPvqo0XURjuNIkkaPHq0TTjhBK1eubPa6la/6xS9+obq6Or333nsaNGiQJOmaa67RiSeeqDvuuENr1qxpFN+zZ0+99dZbobqDwaB+//vfq7S0VOnp6cbt2dq3b5+ys7ObHF3JycmRpKjuPbW1tVq4cKEGDhyoM844o815fvKTn+jrX/96m68n+qqkpCTNmDEjNNhs2rRJDz/8sL71rW/pww8/VF5eXli20xYcsUGbDB06NDTUSNKoUaMkHTnU3jDUHP34F198IelIA/nHP/6ha665JjTUSNI555yjU089tTNKB6JebGxsaKgJBoM6dOiQ6uvrNWLECH344YdN4qdMmRIaaqQjf4kcNWqUXn/9dUnSoUOH9M477+jyyy9XeXm5Dh48qIMHD6q4uFgTJ07U9u3bj/mBeezYsXIcp113RzrWhcsJCQmqrq5uc+6O9utf/1pvv/227r///kYfADvChRdeqP79++u2227Tiy++qC+//FJ/+ctf9POf/1xxcXFRvZ/Q2Pjx49W7d2/l5eVp6tSpSklJ0YoVKxr9rErSDTfc0Oj/ly9frvT0dJ1//vmhn9WDBw9q+PDhSklJCZ2S+vbbb6u2tlY333xzow/tt9xyi7G2zZs3q6CgQLfcckuT93RbTq8KBAJ66623NGXKlNBQIx0ZHq688kq99957Kisra/RvrrvuukbbGjNmjAKBgL788svQYzNmzJDjOO2641h1dXWzNz9KSEgIPR+tbrrpJv3zn//Uo48+2uYbNeTn5+uvf/2rFi5cGLa6Lr/8cj355JO65pprNGXKFN1777168803VVxcrF/96ldh205bcMQGbXL08CIp9NeVr07pDY83nBfc0LC+9rWvNcn5ta99rdkPbUB39NRTT+mhhx7S1q1bG5168tU70EjS4MGDmzx2wgkn6C9/+YukI0d0HMfR3LlzNXfu3Ga3d+DAgSYfuMIpMTFRtbW1zT5XU1MT1tMjwumFF17QL37xC1177bVNPoB2hISEBL322mu6/PLLQ6cl+Xw+Pfjgg/rVr37V6A9CiG6LFi3SCSecoLi4OGVnZ+vEE09scj1YXFyc+vbt2+ix7du3q7S0tMnRzQYHDhyQ9J/fp1/9+e/du7d69OhxzNoaTos75ZRT7L+hYygqKlJVVVXoiOPRTjrpJAWDQe3evbvRNSRf/RzRUPNXryNqr8TExNApnkdruH17tPaeBQsW6I9//KPuvfdeXXjhhW3KUV9frx/96Ee6+uqr23XEx8ZZZ52lUaNG6e233+7Q7Zgw2KBNYmNjW/V4w6FtAGbPPPOMZsyYoSlTpuj2229XVlaWYmNjNX/+/NAHktZouMbttttu08SJE5uNae6PDeGUk5OjQCCgAwcONPrAVltbq+LiYuXm5nbo9tti5cqVuuaaa3TRRRdpyZIlnbbdk08+WVu2bNE///lPHT58WEOHDlViYqJuvfVWnXPOOZ1WB9pn5MiRTa4p+yqfz9dk2AkGg8rKytKzzz7b7L/p3bt32GqMpM76vJCTk6P8/Hw5jtPoCFHDLZqjsfcsXbpUP/3pT/XDH/5Qv/jFL9qc5+mnn9a2bdv02GOPNVlkvby8XDt37lRWVlbYbj+el5enbdu2hSVXWzHYoFM1XEOzY8eOJs819xjQHf3P//yPBg0apBdffLHRL+J58+Y1G9/cBZv/+te/QncZbDg1xOv1avz48eEv2MLpp58uSfrggw8a/fXxgw8+UDAYDD0fLTZu3KhLLrlEI0aM0F/+8pdOX6/D4/E0+uv266+/rmAwGLHXD53n+OOP19tvv60zzzzzmEcTGn6fbt++vdHpX0VFRcajHscff7wkacuWLcd8T9melta7d28lJSU1+6F269atiomJidh1F6effroef/xxffbZZxo6dGjo8YYbGkRb73n55Zf1gx/8QJdeemnornRttWvXLtXV1enMM89s8tzTTz+tp59+WitWrNCUKVPatZ0GX3zxRcQHb66xQafKzc3VKaecoqeffloVFRWhx9esWaN//OMfEawMiB4Nf8k8+i+XGzdubPG2pC+99FKja2Tef/99bdy4MXShe1ZWlsaOHavHHnus2YXkvnqL1a8Kx+2ezz33XGVmZmrx4sWNHl+8eLGSkpKarBQeSZ999pkuuugiDRgwQK+++mrET1Wprq7W3LlzlZOTo+9///sRrQUd7/LLL1cgENC9997b5Ln6+nqVlJRIOnINj9fr1SOPPNKoV9hcS/GNb3xDAwcO1MKFC0P5GhydKzk5WZKaxHxVbGysJkyYoJdffrnRkYH9+/frueee01lnnaW0tDRjXV8Vjts9X3zxxfJ6vfrDH/4QesxxHC1ZskTHHXdcs7d3j5S1a9dq6tSpOvvss/Xss8+2+1b2U6dO1YoVK5p8SUeu51uxYkXoWujWaO53xuuvv65NmzbpggsuaFfN7cURG3S6X//617r44ot15plnaubMmTp8+LAeffRRnXLKKY2GHaAre+KJJ/TGG280efzHP/6xvv3tb+vFF1/UJZdcoosuukgFBQVasmSJhg4d2uzPyNe+9jWdddZZuuGGG+T3+7Vw4UL17NlTd9xxRyhm0aJFOuuss3Tqqadq1qxZGjRokPbv36/169drz549+vjjj1us9f3339e4ceM0b968Nt9AIDExUffee69mz56t733ve5o4caLeffddPfPMM/rVr37VaI2X1atXW29v7dq1Wrt2raQjv2wrKyt13333STqy2vrZZ58divV4PDrnnHOarOVxtPLyck2cOFGHDx/W7bff3mR9neOPP77RjVPGjh2rNWvWWJ0+01BXwzojy5Yt03vvvSdJjU43ufzyy5Wbm6uhQ4eqrKxMTzzxhL744gu99tprSk1NNW4H7nbOOefo+uuv1/z58/XRRx9pwoQJ8nq92r59u5YvX67f/e53+u53v6vevXvrtttu0/z58/Xtb39bF154oTZv3qz//d//Nd4aOCYmRosXL9bkyZN1+umna+bMmcrJydHWrVv16aef6s0335R05HbskvSjH/1IEydOVGxsbIt31rrvvvu0cuVKnXXWWbrxxhsVFxenxx57TH6/Xw8++GCb9sWKFSs0c+ZMPfnkk22+gUDfvn11yy23aMGCBaqrq9MZZ5yhl156Se+++66effbZRqfELV261Hp7r7zySqhv1tXV6ZNPPgn9jH/nO9/RaaedJknauXOnBg4cqOnTp2vp0qUt5vvyyy/1ne98Rx6PR9/97ne1fPnyRs+fdtppoZySQkfkv3qK2dGGDBmiIUOGNPvcwIEDmxypse1n3/rWt/T1r39dI0aMUHp6uj788EM98cQTysvL03/9138d8992NAYbdLrJkyfr+eef1913362f/exnGjx4sJYuXaqnnnqq2YXFgK7oq0cuGsyYMUMzZsxQYWGhHnvsMb355psaOnSonnnmGS1fvrzZD+XXXHONYmJitHDhQh04cEAjR47Uo48+GrqdqXTkToYffPCB7rnnHi1dulTFxcXKysrS17/+dd11110d9W02cuONN8rr9eqhhx7S3/72N+Xl5em3v/2tfvzjHzeKaxjejq6/Je+8847uueeeRo813CBh3rx5ocHGNmdxcbF2794tSfrZz37W5Pnp06c3GmwqKirUp08fY51H19XgiSeeCP330YPNiBEj9OSTT+qxxx5TYmKixowZo+eeey7qTplBx1myZImGDx+uxx57TP/1X/+luLg4DRgwQNOmTWt0WtF9992nhIQELVmyRPn5+Ro1apTeeustqyOgEydOVH5+vu655x499NBDCgaDOv744zVr1qxQzKWXXqqbb75Zf/7zn/XMM8/IcZwWB5uTTz5Z7777ru68807Nnz9fwWBQo0aN0jPPPNOmowLhdP/996tHjx567LHHtHTpUg0ePFjPPPNMo9tpS63rPX/961/11FNPhf5/8+bNoTVx+vbtGxpCbHMWFBSEjkzNnj27yfPz5s1rNNhUVlaG/dpI2352xRVX6LXXXtNbb72lqqoq5eTkaNasWZo3b56ys7PDWlOrOUCUGDZsmDN+/PhIlwGgHfr37+9MnTrVKSoqcioqKtqU4/bbb3f69u3r1NTUhK2u1157zfF4PM4nn3wStpxlZWVOXFyc8+ijj4YtZ2tUV1c7RUVFzu233+5IcoqKiiJSBxANJDm33367U1RU5FRVVbUpx/e+9z3njDPOCGtdixYtcpKTk53CwsKw5fz0008dSc6rr74atpwd0c+CwaBTVFTkfPjhh44kZ8GCBWHL3RKusUGnq6urU319faPHVq9erY8//ji0iCcA9/rzn/+s3r1766c//Wmb/n1+fr7mzp3b7NoTbZWfn6+pU6eGdb2stWvX6rjjjmv0F+7OtGTJEvXu3VsLFiyIyPaBaLNgwQL17t27TRfdO46j1atXh04nC5f8/Hz96Ec/CuuRjPz8fI0ePTqs1yZ2RD8rLS1V79699Y1vfCNsOU08jsN9eNG5du7cqfHjx2vatGnKzc3V1q1btWTJEqWnp2vLli3q2bNnpEsE0Ebr1q0LLXiXl5fX7LoWCI/du3c3ugvVOeecI6/XG8GKgMg5ev2UE044ock6Oeh89fX1jU6f7ozXhcEGna60tFTXXXed1q1bp6KiIiUnJ+u8887T/fffH7oFJQAAANAaDDYAAAAAXI9rbAAAAAC4XtTd7jkYDGrv3r1KTU21XvEWQMdwHEfl5eXKzc1t90JhnYk+AkQPN/YReggQPVrTQ6JusNm7d6/y8vIiXQaAo+zevVt9+/aNdBnW6CNA9HFTH6GHANHHpodE3WDTsKrya6sWKDklscW4mt12pX9StdsY84/tdotC7ikoNsYk7yqzyuVNyDTGVMQmWeVK9QaMMXE5dn8lS8803161ZyDZKlfPPPMiT1XxhVa5yr807699hf+2ylVWUmCMKSyqtcqVdnifMabasXuvJveqM8ZkJtjdLvJwnPnOSBU1VcaY+vqg3l/zhetWO2+o1xubI4+n/X8hrq03v87xceYF3dB66fHR+UG4tHZPpEtwDccJqi6wz1V9pKHW0b6rFOeJj3A1QPdW79Rqvf9Zqx7SYYPNokWLtGDBAhUWFmrYsGF65JFHNHLkSOO/azjkm5ySqJRjDDaxSXalJyrBGBOfYHd7zLh48za9cbFWubxei1yxdnV5veYPbt54uw93Nvsiod6uyScmmoekYLxdrtoEc674eNv9ZX6N4ixfx7hY836Ns1wuyhtnjou3qP1ILovvsd4ul6SInIrR1h4i/adejycmLIONZP7+w7MdfFWMJ+r+/iaJ17st3NRHGmqN88Qz2ABRwqaHdEhnfuGFFzRnzhzNmzdPH374oYYNG6aJEyfqwIEDHbE5AF0MPQRAe9FHgO6nQwabhx9+WLNmzdLMmTM1dOhQLVmyRElJSXriiSeaxPr9fpWVlTX6AtC9taaHSPQRAE3xWQTofsI+2NTW1mrTpk0aP378fzYSE6Px48dr/fr1TeLnz5+v9PT00BcX6wHdW2t7iEQfAdAYn0WA7insg83BgwcVCASUnd34Iufs7GwVFja9UPzOO+9UaWlp6Gv3bvPF/gC6rtb2EIk+AqAxPosA3VPEr8r0+Xzy+cwXhgNAS+gjANqDHgJ0DWE/YtOrVy/FxsZq//79jR7fv3+/+vQx3/4XQPdGDwHQXvQRoHsK+xGb+Ph4DR8+XKtWrdKUKVMkHVnBd9WqVbrpppvsC0uMVVxSy7ejLfIfsspTsXWvMebA3+vtajpgngP9gRKrXJnxjnl7PrvbF8dnmevPSO1plctTZl6jxptUaZUrs9K871PizLfjliRfsnmtngTLuxd/4TO/jv/y2L0nyg4fNsbkptitR5SQ3M8Yk+Kx21/7K83fY9lh87pMgUDQanvhFK4eEk4+b25EthttMuLN71EgGkRjHwHQ8TrkVLQ5c+Zo+vTpGjFihEaOHKmFCxeqsrJSM2fO7IjNAehi6CEA2os+AnQ/HTLYXHHFFSoqKtJdd92lwsJCnX766XrjjTeaXMQHAM2hhwBoL/oI0P102M0DbrrpJg73AmgzegiA9qKPAN1LhyzQCQAAAACdicEGAAAAgOsx2AAAAABwPQYbAAAAAK7HYAMAAADA9RhsAAAAALheh93uub0OxqSqOqblFdsr68us8iT3yjLGpA4wx0hScUyBMSbD77fKlZVUaRHkWOVKTk8xxjgJiVa5qixm3VjH7nusKDTHHNpbY5UrznfIGBOfVmeVq7QqaIwJ7K+wypXqTzfG+DLt9r23Mt4Ysz1xv1WuPX7zOg2xpT5jTCBg3lc4wl+31yrO580N2zYz4vuFLReAjpNf/XikS2izcYk/6PRtrqwcE7Zc5ye/a4x564/LwrY9t/NOs/uM17nsPg9LHLEBAAAA0AUw2AAAAABwPQYbAAAAAK7HYAMAAADA9RhsAAAAALgegw0AAAAA12OwAQAAAOB6DDYAAAAAXC9qF+hMquqhpJjkFp8flOe1ylM5NNMYE5Nptxjj/l6lxpiafZaLCFUeNobEBexS9Sgx74uKgF1dgaB5QUZPjd08XB8wL75ZEzDvU0nKcszfY0Gy3WKSe/21xpjyGrud39trXhy1OtDHKldtXb0xpjDDbrHPA96WF7dtkNGnrzEmWF8vfbHPapvRqLZ+nyRPu/PYLKppu/Ami2pGt5LaXZEuAYgq4VwsM5xsFt60NWHW1VZxLOQZ/ThiAwAAAMD1GGwAAAAAuB6DDQAAAADXY7ABAAAA4HoMNgAAAABcj8EGAAAAgOsx2AAAAABwPQYbAAAAAK7HYAMAAADA9eIiXUBLRvVOUVpqy6u6fxbjWOWprCo0xqRVlVjl8nvqjDH76uxyBUvKjTFxfczbk6S6BHNcYtC8qr0k1fpTjTH7vZYrucd6jSFxgaBVqoMyf4+HYyqtclVavOtL4outclUFexljfE61VS5/mt8Yk2z3tldWXJkxpjxg3hFBx+71cSufNzdsuTLi+4UtFwB0hvrgU5EuoVnnJ78b6RLgUhyxAQAAAOB6DDYAAAAAXI/BBgAAAIDrMdgAAAAAcD0GGwAAAACux2ADAAAAwPUYbAAAAAC4HoMNAAAAANeL2gU6tyhWKYpt8flNO3ZZ5YndsccYU1V80CpX2ZeHjTHeKvMii5IUm2yO8STZLYRZXx0wx1guEhlvMer2VssLpx7NqxpjTGJiolWuAxnmHVa12+57LC/MNMb443xWucpSkowxaT7zYpmS5K0wr75ZlVRilSsh1vw+rIvpYYwJxnTtBToBoCuKxMKbLKqJaMARGwAAAACuF/bB5u6775bH42n0NWTIkHBvBkAXRQ8B0F70EaB76pBT0U4++WS9/fbb/9lIXNSe8QYgCtFDALQXfQTofjrkpzwuLk59+vTpiNQAugF6CID2oo8A3U+HXGOzfft25ebmatCgQbrqqqu0a1fLF/r7/X6VlZU1+gLQvbWmh0j0EQBN8VkE6H7CPtiMGjVKS5cu1RtvvKHFixeroKBAY8aMUXl5ebPx8+fPV3p6eugrLy8v3CUBcJHW9hCJPgKgMT6LAN2Tx3Ec8z1m26GkpET9+/fXww8/rGuvvbbJ836/X37/f25NW1ZWpry8PK0reE8pqS3fVnjTho+tth+74wtjjO3tngstbvdcW2WXKzbefDve+Ox6q1xJ1eZbJtc78Va5PDHmXME4u9s9+yxu9xyXYPdXMZvbPX+x+99Wuf7viwRjzL/3bbbKNVDZxpg0n90twL0p4bvds0fmbZbXWNzuuT6ogrX7VVpaqrS0NKtth5uph0gt95Ejf7tp+bbpPm9u2OrMiO8XtlyInJJau6UEYM9xgqqt/3dU95GWesiYhJmK89j9/jyW/OrH252jNbjdc8d464/LIl1Ch/NOs/vM0rkcSUGrHtLhV9JlZGTohBNO0I4dO5p93ufzyeezWzMEQPdj6iESfQTAsfFZBOgeOnwdm4qKCn3++efKycnp6E0B6ILoIQDaiz4CdA9hP2Jz2223afLkyerfv7/27t2refPmKTY2Vt///vdblefJt1YpPvEYpwxtq7DKM7iy1hhT5imyyhWojjXGxATsDuHV1ZlXdPfuNp/KJUklFvOpJ9nupa6NKTXGZCaYYyQpNmA+ra3Qaz7FTJL2F5rrLzlslyuxpOVrNRr099n98vMFkowx/ji7sz0ri80xtZZHiFNKze8db3qVMSZQ36FnqjYrXD3Ehr9ub/iScSpa1OM0s+6jM/tINOoOp4WFU3c4xcxW3TPhO3IZidPawj7Y7NmzR9///vdVXFys3r1766yzztKGDRvUu3fvcG8KQBdEDwHQXvQRoHsK+2Dz5z//OdwpAXQj9BAA7UUfAbqnDr/GBgAAAAA6GoMNAAAAANdjsAEAAADgegw2AAAAAFyPwQYAAACA6zHYAAAAAHC9sN/uOVz+XZgub0LLCzwm9rArPSWhxBgTf8DuvvZxceZFNQ875sUfJamy9JAxpjbuGAuUHh3nNddVV25ejFGSqg95jTFOdrxVruQs8+KONdX1VrmK6s0LslbFllnlSg5Y7HuPeTFWSQqkHjTG+PdXWuWqKzPv12C1+bWWJH+JxxgTm2Gx7z2dv0BnNMpO/makSwDgYuMSfxC2XPnVj4ctF9AWkVh40xZHbAAAAAC4HoMNAAAAANdjsAEAAADgegw2AAAAAFyPwQYAAACA6zHYAAAAAHA9BhsAAAAArsdgAwAAAMD1GGwAAAAAuF5cpAtoycm9/PIltjx3BWsSrfL06mVeXT0mq49VrpoC88r2pf+yWM1dUqXMK8h742qtcjky11W8r9IqV2WJRf3lKVa5kvxJxphgtt1sXVldYg5y9lrliu9hXjG3psiurn0e836tTPRY5fIFqowxngq7H9lEb4YxJlCVbI4JBCWZ63Kr7ORvRroEhEFJ7a5IlwBElfzqxyNdQruMS/xBp25vwqyrreLe+uOyDq4k8rzTzJ+RohlHbAAAAAC4HoMNAAAAANdjsAEAAADgegw2AAAAAFyPwQYAAACA6zHYAAAAAHA9BhsAAAAArsdgAwAAAMD1onaBzn5eKdHb8vOxSXaLRKb2dowxB2PTrHL568xzYOyuHla5kg4XGWOqg9VWuRzHvFhp5W7zfpCkwzXmbTqxh61ypceaFxitSE61ylVWYX6N4g6WWuWKqzN/j367tVF1yJ9gDoq3S1arWGNMssdnlSslpcQYs6/CXHswaF5INprFx+XI4+HvNwAQDTp74c1ws1nIM1oX8XT7wpu2+I0PAAAAwPUYbAAAAAC4HoMNAAAAANdjsAEAAADgegw2AAAAAFyPwQYAAACA6zHYAAAAAHA9BhsAAAAArsdgAwAAAMD14iJdQEs83n/LE9/yKuup6XaruaclJBljKoPmGEn60qk0xsTFF1rligukGmP2eByrXH6nzBhTGeuxylXvLTHGFMbbrUbv91cYY+LKzDGSVHPY/FYtKQ/Y5SrqZYyJPWyVShm96o0xlSnFVrnq/RnGmNgsu/fE/kAfY0xM2SFzoqDd9tA9lNTuinQJQLc3LvEHkS4BxzBh1tVWcW/9cVnYtumd5g9bLrfjiA0AAAAA12v1YLN27VpNnjxZubm58ng8eumllxo97ziO7rrrLuXk5CgxMVHjx4/X9u3bw1UvAJejhwBoL/oIgOa0erCprKzUsGHDtGjRomaff/DBB/X73/9eS5Ys0caNG5WcnKyJEyeqpqam3cUCcD96CID2oo8AaE6rr7GZNGmSJk2a1OxzjuNo4cKF+sUvfqGLL75YkvT0008rOztbL730kqZOndrk3/j9fvn9/zk3sKzMfL0IAPcKdw+R6CNAd8NnEQDNCes1NgUFBSosLNT48eNDj6Wnp2vUqFFav359s/9m/vz5Sk9PD33l5eWFsyQALtKWHiLRRwD8B59FgO4rrINNYeGRO4JlZ2c3ejw7Ozv03FfdeeedKi0tDX3t3r07nCUBcJG29BCJPgLgP/gsAnRfEb/ds8/nk8/X8m2dAcCEPgKgPeghQNcQ1iM2ffocWTtj//79jR7fv39/6DkAaAk9BEB70UeA7iusR2wGDhyoPn36aNWqVTr99NMlHbkAb+PGjbrhhhtalSvFf0hJMfEtPh+TYrcYkac21xxTlWCVq77evPhmRrrdyo6eAYnGGL/fHCNJ9X7zvtjVr8oqV+WOdGNMfEnLr8vRAhmlxpjC/XaLalbKXFe1125OLy72GmPias2LsUpS37hkY0zPZLvXMa7evIhqTcDugtbCSvMCthnBFGNMMBiUZPfeCYdw9hAbtgtOZsT3C1suAB2rs/sI0FFYeLP1Wj3YVFRUaMeOHaH/Lygo0EcffaTMzEz169dPt9xyi+677z4NHjxYAwcO1Ny5c5Wbm6spU6aEs24ALkUPAdBe9BEAzWn1YPPBBx9o3Lhxof+fM2eOJGn69OlaunSp7rjjDlVWVuq6665TSUmJzjrrLL3xxhtKSLA7KgKga6OHAGgv+giA5ngcx3EiXcTRysrKlJ6erieXTFNSYsunPMX1Mp9GI0mpSeZT0fZVZVnl+se/zKeaxO7cZJXLc9h8elKh3+7Uqnp/iTFmV7HdKXIlO8xx8VV2p6IlDjCfilbks8tVqUxjTHWg2ipX8T/CeCraAHP9MT2DVrniSi1ORUsI46lodeY8wWBQRXuLVFpaqrS0NKttR4OGPhIfd5w8nvZfSsipaEDbOU5QtfX/dlUfaeghYxJmKs5j93sKaI23/rjMGMOpaA0cSUGrHhLWmwcAAAAAQCQw2AAAAABwPQYbAAAAAK7HYAMAAADA9RhsAAAAALgegw0AAAAA12v1OjadprZKim35frSBQ3all5YfMsbUOHYrq8fa3KWyn/n20pIUm2WuK3Ov3S0mCw75jDG1leYYSfLX9TbnUqxdrnhz/dWyq6umynwr5Ji4CqtcMRnmWyGnxgascvXJyjbHZNi9jnF15m0WZWRY5UrOMN/62rffvL1AIKAiFVltsyvjVs4A2mNl5Ziw5To/+d2w5XIzm9slS9KEWVd3cCVtw62cOwZHbAAAAAC4HoMNAAAAANdjsAEAAADgegw2AAAAAFyPwQYAAACA6zHYAAAAAHA9BhsAAAAArsdgAwAAAMD1onaBzp17Y5WQ0PJCkClJX1rlqY4tN8YkpKdY5aqPsVhMMsVuMcayVPMil9XV5tolyakzv4xOrxyrXJ6geTHG3ua1MiVJSZn9jTGJcXYLdAYPmRdI9HrtFg4dkOo1xvhqHatcB3onG2MSYuxex97Hmf/OkN7L7kc2KdjDGOOkHzbG1NVJ+sJqk0C34q/ba4zxee0WbEbXx6KakWO7kGfnM3/+YRHP1uOIDQAAAADXY7ABAAAA4HoMNgAAAABcj8EGAAAAgOsx2AAAAABwPQYbAAAAAK7HYAMAAADA9RhsAAAAALgegw0AAAAA17NbxjwCipUinxPf4vNf1tdY5fFWm1dXHxhXYZUr1ZNgjDkcsEolOdXGkECK3fdYU1prjImpTrHK5Y0xf4++QelWuRJ85vpjD9mtquuNMW8zpfKQVS71NH+PMfF2+77K/5kxxu9Ltsrl75FojlGGVa5grMcY42SbVz0O1NZbbQ/obnze3EiXALhOfvXjVnF1z5h/P3UHtvvBO83us1Q0svkey6oc9bzO/LlZ4ogNAAAAgC6AwQYAAACA6zHYAAAAAHA9BhsAAAAArsdgAwAAAMD1GGwAAAAAuB6DDQAAAADXY7ABAAAA4HpRu0Cn31MlJ6blxQE9ZXYrYcYlmBdaLK6us8oVCDjGmGCmebFMSYovN9cVF7RbcKnWYjHJhHTzQqWSFEgzL5QUm2le4FKSKvzFxpjKUvM+laTYojRjTIzHvMClJCVbLO4aH2v3o9Enx2uMScuze08EY8zbDJbYLZhZEmPx3nHMueod2xVnAaDrmZwrJca2P8+Le9qfI9rZLr5pw2bBSRbx/A+bfeG58r+tcsXFTG9vOSGReI04YgMAAADA9Vo92Kxdu1aTJ09Wbm6uPB6PXnrppUbPz5gxQx6Pp9HXBRdcEK56AbgcPQRAe9FHADSn1YNNZWWlhg0bpkWLFrUYc8EFF2jfvn2hr+eff75dRQLoOughANqLPgKgOa2+xmbSpEmaNGnSMWN8Pp/69OnT5qIAdF30EADtRR8B0JwOucZm9erVysrK0oknnqgbbrhBxcUtX0Tu9/tVVlbW6AtA99aaHiLRRwA0xWcRoPsJ+2BzwQUX6Omnn9aqVav0wAMPaM2aNZo0aZICgebvrjR//nylp6eHvvLy8sJdEgAXaW0PkegjABrjswjQPYX9ds9Tp04N/fepp56q0047Tccff7xWr16t8847r0n8nXfeqTlz5oT+v6ysjIYCdGOt7SESfQRAY3wWAbqnDr/d86BBg9SrVy/t2LGj2ed9Pp/S0tIafQFAA1MPkegjAI6NzyJA99Dhg82ePXtUXFysnJycjt4UgC6IHgKgvegjQPfQ6lPRKioqGv3Fo6CgQB999JEyMzOVmZmpe+65R5dddpn69Omjzz//XHfccYe+9rWvaeLEia3aTvWuTxSIb3m536ScDKs8MX7zX12qa+1Wc0+UeZX55BrHKpe3rtQYE1NnlUqlBeZlkasrLFail5R+XKIxJjamxCrXl55jX/AtSXVej1WuKidojPFXZ1vlSvWZ5/ny5H1WuVK8xxljqqpaPtJwtLo082vk1JvfN5LkqTa/p2Pqk8zbq7P72WiNzuohALquzuojr+yV4ux+TbXbpX3t4l7c07F1uIV3mt3nGht1z/jClisSJsy62hiz8kq7XG7fF60ebD744AONGzcu9P8N56ROnz5dixcv1ieffKKnnnpKJSUlys3N1YQJE3TvvffK53P3jgIQHvQQAO1FHwHQnFYPNmPHjpXjtHxU4s0332xXQQC6NnoIgPaijwBoTodfYwMAAAAAHY3BBgAAAIDrMdgAAAAAcD0GGwAAAACux2ADAAAAwPUYbAAAAAC4Xqtv99xZgiU5CnpbLm/fXvOCjZKUPbTGGBOfbF7EU5L8HvOKmbGqtspVWW++l36lxSKLkhRXZq7L57e7d3+vKvO+qIqttcpVF2derDQ2PcEqV6DWvF9rSuzeE/9ODRhjkpLtVmTz1hwwxlRZLAgqSUl15v1VVWm3AKwnwfy+9/QyL+zqqTXvKwBA+0Xrwpv51Y9HuoRuy2bhTVvnJ79rFffWH8O2yYjgiA0AAAAA12OwAQAAAOB6DDYAAAAAXI/BBgAAAIDrMdgAAAAAcD0GGwAAAACux2ADAAAAwPUYbAAAAAC4HoMNAAAAANeLi3QBLUkfepJ8Pl+Lz5d9aLdEb0l5mTEmK1BplctJsFiFvT7BKlecv9gYU1fst8pVE2euP5CaapWrtrzKnKvOvGK9JKVnmPdXXMohq1yVpSnGGH+C3ZxeEygyxsT4e1nlSowpNcZ4E+OtcpXU1RpjyoLm10eSelWbf7RLKqqNMYF6i/c8AABRqu6Zlj9LdgTvNLvPbuMSf9DBlbTNhFlXG2Pe+uOysG3Pbn851vk4YgMAAADA9RhsAAAAALgegw0AAAAA12OwAQAAAOB6DDYAAAAAXI/BBgAAAIDrMdgAAAAAcD0GGwAAAACuF7ULdOalpishoeXFLhNz66zy7CwxL3p4MLjfKldvn3lBw+r6RKtctY55gc4SmbcnSXXFQWNMbKrdAlXxCeYFTWsq661y5ZWXG2OKvXYLTlaUm/dFStVxVrlqKjzGmOrYEqtcnkzzj5CnsMIuVzDJGJOSUGOVq8LJNMbUW6QKBFigEwC6qvzqxyNdAlzIdhHSSOCIDQAAAADXY7ABAAAA4HoMNgAAAABcj8EGAAAAgOsx2AAAAABwPQYbAAAAAK7HYAMAAADA9RhsAAAAALgegw0AAAAA1zMvmx4hCZl1Skxsee6K6xdvlSc9IdYYs6+40iqX84U5LimlyipXXJm5Lvnr7XLVmVeAja0ptcp1MJBujKmptltxNs6TYoyp2+dY5aor85qDetRZ5UqUOVew3u49caiotzEmJWDxWktykszbrLbMVVN/2BjjjTPXHgxabQ4AgE41LvEHlpHLOrQORBeO2AAAAABwvVYNNvPnz9cZZ5yh1NRUZWVlacqUKdq2bVujmJqaGs2ePVs9e/ZUSkqKLrvsMu3fvz+sRQNwL/oIgPaghwBoSasGmzVr1mj27NnasGGDVq5cqbq6Ok2YMEGVlf85hebWW2/VK6+8ouXLl2vNmjXau3evLr300rAXDsCd6CMA2oMeAqAlrbrG5o033mj0/0uXLlVWVpY2bdqks88+W6WlpfrTn/6k5557Tueee64k6cknn9RJJ52kDRs26Jvf/GaTnH6/X37/f67ZKCsra8v3AcAl6CMA2oMeAqAl7brGprT0yAXpmZmZkqRNmzaprq5O48ePD8UMGTJE/fr10/r165vNMX/+fKWnp4e+8vLy2lMSAJehjwBoD3oIgAZtHmyCwaBuueUWnXnmmTrllFMkSYWFhYqPj1dGRkaj2OzsbBUWFjab584771RpaWnoa/fu3W0tCYDL0EcAtAc9BMDR2ny759mzZ2vLli1677332lWAz+eTz+drVw4A7kQfAdAe9BAAR2vTEZubbrpJr776qvLz89W3b9/Q43369FFtba1KSkoaxe/fv199+vRpV6EAuhb6CID2oIcA+KpWHbFxHEc333yzVqxYodWrV2vgwIGNnh8+fLi8Xq9WrVqlyy67TJK0bds27dq1S6NHj25VYXX9ByouObHF55NL/mWVp1IZxpiyA5lWucp2B4wxvoQSq1xp8eYFRp1Mj1WuhLQ0Y0xJnTlGkkoDFcaYuNhqq1yecvPbq8xvXkhSkmIrWn4vNIjPsltNMlhvXkQ1yWu3EGZ8tnmx0uRyu8VkD9SY931sTLJVroQy836t9JoXgA0Gwr9CZ2f2kc7kr9trFefz5nZwJUDX1lV7SHdgv6hm+EyYdXWnbm+c+eOK69m+jvnVj3dwJU21arCZPXu2nnvuOb388stKTU0Nnauanp6uxMREpaen69prr9WcOXOUmZmptLQ03XzzzRo9enSzdyEB0P3QRwC0Bz0EQEtaNdgsXrxYkjR27NhGjz/55JOaMWOGJOm3v/2tYmJidNlll8nv92vixIn6wx/+EJZiAbgffQRAe9BDALSk1aeimSQkJGjRokVatGhRm4sC0HXRRwC0Bz0EQEvatY4NAAAAAEQDBhsAAAAArsdgAwAAAMD1GGwAAAAAuB6DDQAAAADXY7ABAAAA4Hqtut1zZ4rrM1JxKSktPl9dUGOVp6TKvJq7U+K1KypQZwwpKqy1SlUWPGiMyUzuaZWrIibJvL2agFWuYFmpMabcY5erzjGvbB+jeKtcPWsTzEF7zbcAlSRfkvl1jI8zx0hSboL5bwM9k1t+Hx/thIODjDG+XkGrXPvTM40xcV7z91hXF9DyHVab7PZ83lyrOH/d3rDlAtqi0j+/U7dXVlalzIzrOnWb0SacK7DXPeMLWy7vtLClCqu3/rgs0iW0mXea3ypuXOIPOriSyLP5HsP5syFxxAYAAABAF8BgAwAAAMD1GGwAAAAAuB6DDQAAAADXY7ABAAAA4HoMNgAAAABcj8EGAAAAgOsx2AAAAABwvahdoHPgCYOVnJbW4vNVNXYLFWpXrDEk7UCZVarYHpXGmLiDdgtnVQbNi0kGE+y+x5LdRcaYsnq7hUPj0qqNMbG1Hqtc8THmBSBLvrRYeFNSps88g9ck2S3Q6S0yL8jqpFr+aFSYFyFNTbfbX9l5GcaY/pk5Vrlqcs37q7be/P6q9tdq+crPrLYJRDsWR0VXYLsApI1oXSRywqyrjTHhXMQznPsUrWPzHqx3avVuzZNW+ThiAwAAAMD1GGwAAAAAuB6DDQAAAADXY7ABAAAA4HoMNgAAAABcj8EGAAAAgOsx2AAAAABwPQYbAAAAAK4XdQt0Os6RRRaryo69aGZNRYVVvlq/ecHJujq7xSuD9ebFGOsDAatc9UHz4oh1FgsoSlIgYI4LBOwWr/TYxNl9i/JYpAo6dnXVOxbfo8Wip5LksdhmrMXrI9m9Rv468/tGkmrizHFVtXbvVX+NxQKdFu+bav+RRVYdy9cpWjTU61i8bzqfeV9GZ91dAfteksrKqjp5e0d+D7upjzTUWu/Y9VyLjGHKE17h+/46X1lVOPdp578+bt73na1hX9n0EI8TZZ1mz549ysvLi3QZAI6ye/du9e3bN9JlWKOPANHHTX2EHgJEH5seEnWDTTAY1N69e5WamiqPxyNJKisrU15ennbv3q20tLQIV9h6bq7fzbVL7q4/Gmp3HEfl5eXKzc1VTIx7zlztan3EzbVL7q7fzbVL0VG/G/tIV+shkrvrd3Ptkrvrj4baW9NDou5UtJiYmBansbS0NNe9IY7m5vrdXLvk7vojXXt6enrEtt1WXbWPuLl2yd31u7l2KfL1u62PdNUeIrm7fjfXLrm7/kjXbttD3PGnEwAAAAA4BgYbAAAAAK7nisHG5/Np3rx58vl8kS6lTdxcv5trl9xdv5trj0Zu3p9url1yd/1url1yf/3RxO370s31u7l2yd31u632qLt5AAAAAAC0liuO2AAAAADAsTDYAAAAAHA9BhsAAAAArsdgAwAAAMD1GGwAAAAAuJ4rBptFixZpwIABSkhI0KhRo/T+++9HuiSju+++Wx6Pp9HXkCFDIl1Wi9auXavJkycrNzdXHo9HL730UqPnHcfRXXfdpZycHCUmJmr8+PHavn17ZIr9ClPtM2bMaPJaXHDBBZEp9ivmz5+vM844Q6mpqcrKytKUKVO0bdu2RjE1NTWaPXu2evbsqZSUFF122WXav39/hCp2Jzf2EMldfcTNPUSij8DMjX3ETT1EcncfoYdEh6gfbF544QXNmTNH8+bN04cffqhhw4Zp4sSJOnDgQKRLMzr55JO1b9++0Nd7770X6ZJaVFlZqWHDhmnRokXNPv/ggw/q97//vZYsWaKNGzcqOTlZEydOVE1NTSdX2pSpdkm64IILGr0Wzz//fCdW2LI1a9Zo9uzZ2rBhg1auXKm6ujpNmDBBlZWVoZhbb71Vr7zyipYvX641a9Zo7969uvTSSyNYtbu4uYdI7ukjbu4hEn0Ex+bmPuKWHiK5u4/QQ6KEE+VGjhzpzJ49O/T/gUDAyc3NdebPnx/BqszmzZvnDBs2LNJltIkkZ8WKFaH/DwaDTp8+fZwFCxaEHispKXF8Pp/z/PPPR6DCln21dsdxnOnTpzsXX3xxROpprQMHDjiSnDVr1jiOc2Q/e71eZ/ny5aGYzz77zJHkrF+/PlJluopbe4jjuLePuLmHOA59BE25tY+4tYc4jrv7CD0kcqL6iE1tba02bdqk8ePHhx6LiYnR+PHjtX79+ghWZmf79u3Kzc3VoEGDdNVVV2nXrl2RLqlNCgoKVFhY2Oh1SE9P16hRo1zxOkjS6tWrlZWVpRNPPFE33HCDiouLI11Ss0pLSyVJmZmZkqRNmzaprq6u0b4fMmSI+vXr55p9H0lu7yFS1+gjXaGHSPSR7srtfaQr9BCpa/QRekjHi+rB5uDBgwoEAsrOzm70eHZ2tgoLCyNUlZ1Ro0Zp6dKleuONN7R48WIVFBRozJgxKi8vj3Rprdawr934OkhHDv0+/fTTWrVqlR544AGtWbNGkyZNUiAQiHRpjQSDQd1yyy0688wzdcopp0g6su/j4+OVkZHRKNYt+z7S3NxDpK7TR9zeQyT6SHfm5j7SVXqI5P4+Qg/pHHGRLqCrmjRpUui/TzvtNI0aNUr9+/fXX/7yF1177bURrKz7mTp1aui/Tz31VJ122mk6/vjjtXr1ap133nkRrKyx2bNna8uWLVF9/jM6F30ketBH4Eb0kOhBD+kcUX3EplevXoqNjW1y14X9+/erT58+EaqqbTIyMnTCCSdox44dkS6l1Rr2dVd4HSRp0KBB6tWrV1S9FjfddJNeffVV5efnq2/fvqHH+/Tpo9raWpWUlDSKd+u+72xdqYdI7u0jXa2HSPSR7qQr9RG39hCp6/URekjHiOrBJj4+XsOHD9eqVatCjwWDQa1atUqjR4+OYGWtV1FRoc8//1w5OTmRLqXVBg4cqD59+jR6HcrKyrRx40bXvQ6StGfPHhUXF0fFa+E4jm666SatWLFC77zzjgYOHNjo+eHDh8vr9Tba99u2bdOuXbtcue87W1fqIZJ7+0hX6yESfaQ76Up9xK09ROp6fYQe0kEifPMCoz//+c+Oz+dzli5d6vzzn/90rrvuOicjI8MpLCyMdGnH9JOf/MRZvXq1U1BQ4Kxbt84ZP36806tXL+fAgQORLq1Z5eXlzubNm53Nmzc7kpyHH37Y2bx5s/Pll186juM4999/v5ORkeG8/PLLzieffOJcfPHFzsCBA53q6uoIV37s2svLy53bbrvNWb9+vVNQUOC8/fbbzje+8Q1n8ODBTk1NTaRLd2644QYnPT3dWb16tbNv377QV1VVVSjmhz/8odOvXz/nnXfecT744ANn9OjRzujRoyNYtbu4tYc4jrv6iJt7iOPQR3Bsbu0jbuohjuPuPkIPiQ5RP9g4juM88sgjTr9+/Zz4+Hhn5MiRzoYNGyJdktEVV1zh5OTkOPHx8c5xxx3nXHHFFc6OHTsiXVaL8vPzHUlNvqZPn+44zpHbLM6dO9fJzs52fD6fc9555znbtm2LbNH/v2PVXlVV5UyYMMHp3bu34/V6nf79+zuzZs2Kml9GzdUtyXnyySdDMdXV1c6NN97o9OjRw0lKSnIuueQSZ9++fZEr2oXc2EMcx119xM09xHHoIzBzYx9xUw9xHHf3EXpIdPA4juOE8wgQAAAAAHS2qL7GBgAAAABsMNgAAAAAcD0GGwAAAACux2ADAAAAwPUYbAAAAAC4HoMNAAAAANdjsAEAAADgegw2AAAAAFyPwQYAAACA6zHYAAAAAHA9BhsAAAAArvf/Aff8aTpr+NN2AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x1000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = next(iter(dataset))\n",
    "img = img.to(device)\n",
    "output = inference(img)\n",
    "\n",
    "fix, axes = plt.subplots(1,3, figsize=(10,10))\n",
    "axes[0].imshow(get_rgb(img[0][:,:-1,:,:].cpu().numpy()))\n",
    "axes[1].imshow(label[0].numpy(), cmap='inferno')\n",
    "axes[2].imshow(output[0].cpu().numpy(), cmap='inferno')\n",
    "\n",
    "axes[0].set_title('img')\n",
    "axes[1].set_title(f'Label: {label[0].unique().tolist()}')\n",
    "axes[2].set_title(f'Prediction: {output[0].int().cpu().unique().tolist()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 24, 24])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 24, 24])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = torch.flatten(output)\n",
    "label = torch.flatten(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2228732638888889"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(label, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.,  ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 0,  ..., 1, 0, 2])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
